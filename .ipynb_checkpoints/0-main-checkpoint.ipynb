{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a701e748",
   "metadata": {},
   "source": [
    "TO DO\n",
    "\n",
    "general implementation\n",
    "    create a graph or diagram to tell whats hapenning\n",
    "    mark all the tasks/steps complete, incomplete, in progress, problems, to do, research etc.\n",
    "    try on a toy problem\n",
    "\n",
    "find new datasets\n",
    "    for different datasets different preprocessing techniques should be applied\n",
    "    RCV1-V2\n",
    "decide on splitting ratio 20 60 20 \n",
    "\n",
    "try different similarity measures \n",
    "    reference paper\n",
    "    cosine\n",
    "    euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b372be",
   "metadata": {},
   "source": [
    "implementation steps\n",
    "\n",
    "+1. reading data and preprocessing\n",
    "2. vectorization\n",
    "    -2.1 embeddings - will try other embeddings, and will search which one is best for datasets\n",
    "    -2.2 dimensionality reduction? (is similarity more accurate when dim. red. done)  - research\n",
    "3. initial classifier to show results\n",
    "4. calculate imbalance ratio and find the ratio of newly labeled data\n",
    "5. oversample dataset using unlabeled set\n",
    "    5.1 find the proper similarity function (eclidean, cosine etc.)\n",
    "        Measurement of Text Similarity: A Survey: a very detailed survey of similarity functions that are used for text data\n",
    "        https://www.kdnuggets.com/2019/01/comparison-text-distance-metrics.html\n",
    "        cosine similarity\n",
    "        minkowski family (euclidean, manhattan)\n",
    "        hamming distance\n",
    "        Jaccard index\n",
    "        Sorensen-dice index\n",
    "        KL divergence\n",
    "        Jensen–Shannon divergence with LDA\n",
    "        Wasserstein distance\n",
    "        SMTP \n",
    "        word mover’s distance\n",
    "    5.2 define a threshold or mechanism to add data for multilabeled set\n",
    "6. train a final classifier to compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "important-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import preprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "import torch\n",
    "from itertools import combinations\n",
    "from sentence_transformers import util\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-packing",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hundred-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm parameters\n",
    "balance_ratio = 0.5\n",
    "sim_type = 'cosine'\n",
    "embedding_method = '' # try different embeddings and find proper one\n",
    "\n",
    "random_state = 1\n",
    "starting_index = 100_000\n",
    "np.random.seed(random_state)\n",
    "\n",
    "majority_path = r'C:\\Users\\IsmailKaraman\\workspace\\data\\privacy_policy_data\\OPP-115_v2\\majority.csv'\n",
    "\n",
    "all_columns = ['Data Retention', 'Data Security', 'Do Not Track', 'First Party Collection/Use', \n",
    "             'International and Specific Audiences', 'Introductory/Generic', 'Policy Change', \n",
    "             'Practice not covered', 'Privacy contact information', 'Third Party Sharing/Collection',\n",
    "             'User Access, Edit and Deletion', 'User Choice/Control']\n",
    "\n",
    "sub_col_names = ['Data Security', 'User Access, Edit and Deletion', 'Policy Change']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5df9753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df['text'] = df['text'].apply(preprocess.preprocess_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61d22048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(text, model_name='stsb-roberta-large'):\n",
    "    \n",
    "    from sentence_transformers import util\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import torch\n",
    "    \n",
    "    model = SentenceTransformer(model_name)\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    vectors = model.encode(text, convert_to_tensor=False, device=device)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca5c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    def calculating_class_weights(y_true):\n",
    "        \n",
    "        number_dim = np.shape(y_true)[1]\n",
    "        weights = []\n",
    "        for i in range(number_dim):\n",
    "            at = compute_class_weight('balanced', [0.,1.], y_true[:, i])\n",
    "            weights.append(dict(zip([0,1], at)))\n",
    "            # weights[i] = compute_class_weight('balanced', [0.,1.], y_true[:, i])))\n",
    "        return weights\n",
    "\n",
    "    # class_weights = calculating_class_weights(y_train.values)\n",
    "    \n",
    "    # Linear SVM\n",
    "    linearSvm = OneVsRestClassifier(LogisticRegression(class_weight='balanced'), n_jobs=-1)\n",
    "    linearSvm.fit(X_train, y_train)\n",
    "    linearSvm_preds = linearSvm.predict(X_test)\n",
    "    print_losses(y_test, linearSvm_preds, 'Linear SVM Classifier')\n",
    "    \n",
    "    print(\"\\033[1m\" + 'LinearSVM results: ' + \"\\033[0m\")\n",
    "    print('-'*30)\n",
    "    hamLoss = hamming_loss(y_test.values, linearSvm_preds)\n",
    "    print('hamLoss: {:.2f}'.format(hamLoss))\n",
    "    acc_score = accuracy_score(y_test.values, linearSvm_preds)\n",
    "    print('Exact Match Ratio: {:.2f}'.format(acc_score))\n",
    "    print('-'*30)\n",
    "    print(\"\\033[1m\" + 'Classification Report' + \"\\033[0m\")\n",
    "    print(classification_report(y_test.values, linearSvm_preds, target_names=list(y_test.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "encouraging-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_imb_ratio(y):\n",
    "\n",
    "    class_ratios = (y.sum() / y.shape[0]).values\n",
    "    return class_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fundamental-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_balancing_num_instance_binary(n_samples, n_total_samples, balance_ratio=0.5):\n",
    "    \n",
    "    if n_samples/n_total_samples > balance_ratio:\n",
    "        print(\"Be careful! Given balancing ratio is lower than the class' imbalance ratio\")\n",
    "        \n",
    "    return int((n_total_samples*balance_ratio - n_samples)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "suspended-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_balancing_num_instance_multiclass(y, balance_ratio):\n",
    "    \n",
    "    oversampling_counts = {}\n",
    "    n_samples = y.shape[0]\n",
    "    n_classes = y.shape[1]\n",
    "    \n",
    "    for col in y.columns:\n",
    "        oversampling_counts[col] = cal_balancing_num_instance_binary(y[col].sum(), n_samples, balance_ratio)\n",
    "    \n",
    "    return oversampling_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9bb30db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    if norm1 == 0:\n",
    "        norm1 += 0.00001\n",
    "    if norm2 == 0:\n",
    "        norm2 += 0.00001   \n",
    "    return np.dot(vec1, vec2)/(norm1*norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c0410f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski_similarity(u, v, p=2):\n",
    "    # minkowski distance is a distance measure but we need a similarity function\n",
    "    if p <= 0:\n",
    "        raise ValueError(\"p must be greater than 0\")\n",
    "    u_v = u - v\n",
    "    dist = np.linalg.norm(u_v, ord=p)\n",
    "    if dist == 0:\n",
    "        dist += 0.0001\n",
    "        \n",
    "    return 1/dist #converting a distance to similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d445edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(vec1, vec2, sim_type=sim_type):\n",
    "    \n",
    "    if sim_type == 'cosine':\n",
    "        similarity = cosine_similarity(vec1, vec2)\n",
    "    if sim_type == 'euclidean':\n",
    "        similarity = minkowski_similarity(vec1, vec2, 2)\n",
    "    if sim_type == 'manhattan':\n",
    "        similarity = minkowski_similarity(vec1, vec2, 1)\n",
    "    if sim_type == 'chebychev ':\n",
    "        similarity = minkowski_similarity(vec1, vec2, np.inf)\n",
    "    if sim_type.startswith('minkowski'):\n",
    "        similarity = minkowski_similarity(vec1, vec2, int(sim_type[-1]))\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "564e8408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_within_class_similarity(vecs, sim_type=sim_type):\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for i,j in list(combinations(vecs.index, 2)):\n",
    "        similarities.append(vector_similarity(vecs.loc[i], vecs.loc[j], sim_type))    \n",
    "            \n",
    "    try:\n",
    "        avg_similarity = sum(similarities)/len(similarities)\n",
    "    except AssertionErrors:\n",
    "        print('Error occured')\n",
    "        \n",
    "    return avg_similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91f0de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_between_vector_and_class(vec, class_vecs, sim_type=sim_type):\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for c_vec in class_vecs:\n",
    "        similarities.append(vector_similarity(vec, c_vec, sim_type))\n",
    "    \n",
    "    try:\n",
    "        avg_similarity = sum(similarities)/len(similarities)\n",
    "    except AssertionErrors:\n",
    "        print('Error occured')\n",
    "        \n",
    "    return avg_similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9b50d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_instances(X_labeled, X_unlabeled, class_similarity):\n",
    "    \n",
    "    new_instances = []\n",
    "    \n",
    "    for idx, instance in X_unlabeled.iteritems():\n",
    "        avg_sim = calculate_similarity_between_vector_and_class(instance, X_labeled)\n",
    "        if avg_sim > class_similarity:\n",
    "            new_instances.append(idx)\n",
    "            \n",
    "    return new_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec4f90cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_class_similarities(X, y):\n",
    "    \n",
    "    class_similarities = {}\n",
    "    for col in y.columns:\n",
    "        indexes = (y[col] == 1).index\n",
    "        aa = X.loc[indexes]\n",
    "        class_similarities[col] = calculate_within_class_similarity(aa) \n",
    "        \n",
    "    return class_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "704564e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_columns(instance, X_labeled, y_labeled, other_columns):\n",
    "    \n",
    "    other_similarities = {}\n",
    "    \n",
    "    for col_name in other_columns:\n",
    "        \n",
    "        indexes = (y_labeled[col_name] == 1).index\n",
    "        \n",
    "        other_similarities[col_name]  = calculate_similarity_between_vector_and_class(instance, X_labeled.loc[indexes])\n",
    "    \n",
    "    return other_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "legal-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_dataset(num_of_new_instances, X_labeled, y_labeled, X_unlabeled, y_unlabeled):\n",
    "    \n",
    "    # giving priority to mostly imbalanced classes\n",
    "    num_of_new_instances = {k: v for k, v in sorted(num_of_new_instances.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    class_similarities = calculate_overall_class_similarities(X_labeled, y_labeled)\n",
    "    \n",
    "    processed_columns = []\n",
    "    \n",
    "    for col_name, num_instance in num_of_new_instances.items():\n",
    "        \n",
    "        # note: we didnt use num_instance\n",
    "        # the instances will be added should not exceed num_instance\n",
    "        \n",
    "        processed_columns.append(col_name)\n",
    "        \n",
    "        if num_instance == 0:\n",
    "            continue\n",
    "        \n",
    "        indexes = (y_labeled[col_name] == 1).index\n",
    "        \n",
    "        \n",
    "        new_instances = find_new_instances(X_labeled.loc[indexes], X_unlabeled, class_similarities[col_name])\n",
    "        \n",
    "        \n",
    "        for instance_index in new_instances:\n",
    "            \n",
    "            instance_X = X_unlabeled.loc[instance_index]\n",
    "            instance_y = y_unlabeled.loc[instance_index] # note: this is for test case\n",
    "            \n",
    "            # defining all labels as 0s\n",
    "            new_labels = {c:0 for c in all_columns}\n",
    "            # changing col_name's label as 1\n",
    "            new_labels[col_name] = 1\n",
    "            \n",
    "            other_columns = [i for i in all_columns if i not in processed_columns]\n",
    "            other_similarities = find_similar_columns(instance_X, X_labeled, y_labeled, other_columns)\n",
    "            \n",
    "            for col, sim in other_similarities.items():\n",
    "                \n",
    "                if sim > class_similarities[col]:\n",
    "                    new_labels[col] = 1\n",
    "            \n",
    "            # starting index of new instances from a big number\n",
    "            instance_new_index = max(starting_index, max(X_labeled.index)) + 1\n",
    "            instance_X_series = pd.Series([instance_X], index=[instance_new_index])\n",
    "            instance_y_series = pd.Series([instance_y], index=[instance_new_index]) # note: this is for test case\n",
    "            \n",
    "            # adding new instance to labeled set\n",
    "            X_labeled = X_labeled.append(instance_X_series)\n",
    "            y_labeled = y_labeled.append(instance_y_series) # note: this is for test case\n",
    "            \n",
    "            # removing new instance from unlabeled set\n",
    "            X_unlabeled.drop(instance_index, inplace=True)\n",
    "            y_unlabeled.drop(instance_index, inplace=True) # note: this is for test case\n",
    "            \n",
    "    \n",
    "    return X_labeled, y_labeled, X_unlabeled, y_unlabeled "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-george",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "566b277e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 808, 1418, 2677, 1786, 2539, 2659, 2127, 1641,  752,   79, 3173,\n",
      "             422, 2159,  458, 1273,  343, 2084,  307, 2745, 2504],\n",
      "           dtype='int64')\n",
      "---\n",
      "Int64Index([ 808, 1418, 2677, 1786, 2539, 2659, 2127, 1641,  752,   79, 3173,\n",
      "             422, 2159,  458, 1273,  343, 2084,  307, 2745, 2504],\n",
      "           dtype='int64')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ISMAIL~1\\AppData\\Local\\Temp/ipykernel_20936/3556683373.py:50: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_labeled = X_labeled.append(instance_X_series)\n",
      "C:\\Users\\ISMAIL~1\\AppData\\Local\\Temp/ipykernel_20936/3556683373.py:51: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_labeled = y_labeled.append(instance_y_series) # note: this is for test case\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can only append a Series if ignore_index=True or if the Series has a name",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ISMAIL~1\\AppData\\Local\\Temp/ipykernel_20936/2479967536.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# -----------------------------------------------------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# oversampling dataset using unlabeled data with the given ratios\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m X_labeled, y_labeled, X_unlabeled, y_unlabeled = oversample_dataset(num_of_new_instances, \n\u001b[0m\u001b[0;32m     39\u001b[0m                                                                     X_labeled, y_labeled, X_unlabeled, y_unlabeled)\n\u001b[0;32m     40\u001b[0m \u001b[1;31m# -----------------------------------------------------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ISMAIL~1\\AppData\\Local\\Temp/ipykernel_20936/3556683373.py\u001b[0m in \u001b[0;36moversample_dataset\u001b[1;34m(num_of_new_instances, X_labeled, y_labeled, X_unlabeled, y_unlabeled)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;31m# adding new instance to labeled set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mX_labeled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_labeled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance_X_series\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0my_labeled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_labeled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance_y_series\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# note: this is for test case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;31m# removing new instance from unlabeled set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   9031\u001b[0m         )\n\u001b[0;32m   9032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9033\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_append\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   9034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9035\u001b[0m     def _append(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_append\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   9047\u001b[0m                 \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9048\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9049\u001b[1;33m                 raise TypeError(\n\u001b[0m\u001b[0;32m   9050\u001b[0m                     \u001b[1;34m\"Can only append a Series if ignore_index=True \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9051\u001b[0m                     \u001b[1;34m\"or if the Series has a name\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can only append a Series if ignore_index=True or if the Series has a name"
     ]
    }
   ],
   "source": [
    "# reading data\n",
    "df = pd.read_csv(majority_path)\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# creating a toy dataset to provide efficiency\n",
    "toy_df = df[(df[all_columns].sum(axis=1)==df[sub_col_names].sum(axis=1))].sample(100, random_state=random_state)\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "X = toy_df['text']\n",
    "y = toy_df[sub_col_names]\n",
    "all_columns = sub_col_names # note: only for toy example\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# reading from a pickle instead of applying vectorization\n",
    "'''\n",
    "X_num = X.apply(vectorize_data)\n",
    "import pickle\n",
    "with open('X_num.p', 'wb') as f:\n",
    "    pickle.dump(X_num, f)     \n",
    "'''\n",
    "with open('X_num.p', 'rb') as f:\n",
    "    X_num = pickle.load(f)\n",
    "\n",
    "assert np.array_equal(X_num.index, X.index), 'read indexesare not true'\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# splitting train(labeled-unlabeled)-test\n",
    "# X_num = X.apply(vectorize_data) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_num, y, test_size=0.2, random_state=random_state, stratify=y)\n",
    "X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(X_train, y_train, test_size=0.75, \n",
    "                                                                  stratify=y_train, random_state=random_state)\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# an initial classifier to see results before applying our method\n",
    "# classifier(X_labeled.values, y_labeled, X_test, y_test)\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# calculation number of instances to balance dataset\n",
    "balance_ratio = 0.5\n",
    "num_of_new_instances = cal_balancing_num_instance_multiclass(y_labeled, balance_ratio)\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# oversampling dataset using unlabeled data with the given ratios\n",
    "X_labeled, y_labeled, X_unlabeled, y_unlabeled = oversample_dataset(num_of_new_instances, \n",
    "                                                                    X_labeled, y_labeled, X_unlabeled, y_unlabeled)\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# check if the result gets better\n",
    "classifier(X_labeled.values, y_labeled, X_test, y_test)\n",
    "# -----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627d62d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_num.p', 'rb') as f:\n",
    "    X_num = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-gnome",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-klein",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-niger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e6f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "all_words = words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1758031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_5len = [word.lower() for word in all_words if len(word)==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-missouri",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for word in words_5len:\n",
    "    if 'h' in word and 'k' in word and 'n' in word:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-behalf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for word in words_5len:\n",
    "    if word.startswith('se') and 'r' in word:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_0 = ''\n",
    "letter_1 = ''\n",
    "letter_2 = 'a'\n",
    "letter_3 = ''\n",
    "letter_4 = ''\n",
    "\n",
    "exist_letters = 'acs'\n",
    "banned_letters = 'trdefou'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [word for word in words_5len for e in exist_letters if e in word]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b866aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [word for word in filtered for b in banned_letters if b in word]\n",
    "filtered = [word for word in filtered if letter_0 and word[0]==letter_0]\n",
    "filtered = [word for word in filtered if letter_1 and word[0]==letter_1]\n",
    "filtered = [word for word in filtered if letter_2 and word[0]==letter_2]\n",
    "filtered = [word for word in filtered if letter_3 and word[0]==letter_3]\n",
    "filtered = [word for word in filtered if letter_4 and word[0]==letter_4]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "if letter_2:\n",
    "    print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ebbe7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for word in words_5len:\n",
    "    if 'o' in word and 'u' in word and 'a' not in word and 'i' not in word and 'd' not in word:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b7269e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
