{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a701e748",
   "metadata": {},
   "source": [
    "TO DO\n",
    "\n",
    "general implementation\n",
    "    create a graph or diagram to tell whats hapenning\n",
    "    mark all the tasks/steps complete, incomplete, in progress, problems, to do, research etc.\n",
    "    try on a toy problem\n",
    "\n",
    "find new datasets\n",
    "    for different datasets different preprocessing techniques should be applied\n",
    "    RCV1-V2\n",
    "decide on splitting ratio 20 60 20 \n",
    "\n",
    "try different similarity measures \n",
    "    reference paper\n",
    "    cosine\n",
    "    euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b372be",
   "metadata": {},
   "source": [
    "implementation steps\n",
    "\n",
    "1. reading data and preprocessing\n",
    "2. vectorization\n",
    "    2.1 embeddings\n",
    "    2.2 dimensionality reduction? (is similarity more accurate when dim. red. done) research\n",
    "3. initial classifier to show results\n",
    "4. calculate imbalance ratio and find the ratio of newly labeled data\n",
    "5. oversample dataset using unlabeled set\n",
    "    5.1 find the proper similarity function (eclidean, cosine etc.)\n",
    "        Measurement of Text Similarity: A Survey: a very detailed survey of similarity functions that are used for text data\n",
    "        https://www.kdnuggets.com/2019/01/comparison-text-distance-metrics.html\n",
    "        cosine similarity\n",
    "        minkowski family (euclidean, manhattan)\n",
    "        hamming distance\n",
    "        Jaccard index\n",
    "        Sorensen-dice index\n",
    "        KL divergence\n",
    "        Jensen–Shannon divergence with LDA\n",
    "        Wasserstein distance\n",
    "        SMTP \n",
    "        word mover’s distance\n",
    "    5.2 define a threshold or mechanism to add data for multilabeled set\n",
    "6. train a final classifier to compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5df9753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df['text'] = df['text'].apply(preprocess.preprocess_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d22048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(text, model_name='stsb-roberta-large'):\n",
    "    \n",
    "    from sentence_transformers import util\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import torch\n",
    "    \n",
    "    model = SentenceTransformer(model_name)\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    vectors = model.encode(text, convert_to_tensor=False, device=device)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca5c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    def calculating_class_weights(y_true):\n",
    "        \n",
    "        number_dim = np.shape(y_true)[1]\n",
    "        weights = []\n",
    "        for i in range(number_dim):\n",
    "            at = compute_class_weight('balanced', [0.,1.], y_true[:, i])\n",
    "            weights.append(dict(zip([0,1], at)))\n",
    "            # weights[i] = compute_class_weight('balanced', [0.,1.], y_true[:, i])))\n",
    "        return weights\n",
    "\n",
    "    # class_weights = calculating_class_weights(y_train.values)\n",
    "    \n",
    "    # Linear SVM\n",
    "    linearSvm = OneVsRestClassifier(LogisticRegression(class_weight='balanced'), n_jobs=-1)\n",
    "    print(X_train)\n",
    "    print(y_train)\n",
    "    linearSvm.fit(X_train.values, y_train)\n",
    "    linearSvm_preds = linearSvm.predict(X_test)\n",
    "    print_losses(y_test, linearSvm_preds, 'Linear SVM Classifier')\n",
    "    \n",
    "    print(\"\\033[1m\" + 'LinearSVM results: ' + \"\\033[0m\")\n",
    "    print('-'*30)\n",
    "    hamLoss = hamming_loss(y_test.values, linearSvm_preds)\n",
    "    print('hamLoss: {:.2f}'.format(hamLoss))\n",
    "    acc_score = accuracy_score(y_test.values, linearSvm_preds)\n",
    "    print('Exact Match Ratio: {:.2f}'.format(acc_score))\n",
    "    print('-'*30)\n",
    "    print(\"\\033[1m\" + 'Classification Report' + \"\\033[0m\")\n",
    "    print(classification_report(y_test.values, linearSvm_preds, target_names=list(y_test.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_imb_ratio(y):\n",
    "\n",
    "    class_ratios = (y.sum() / y.shape[0]).values\n",
    "    return class_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fundamental-planning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2195122 , 5.55555556])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal_balancing_num_instance_binary(n_samples, n_total_samples, balance_ratio=0.5):\n",
    "    \n",
    "    if n_samples/n_total_samples > balance_ratio:\n",
    "        print(\"Be careful! Given balancing ratio is lower than the class' imbalance ratio\")\n",
    "        \n",
    "    return int((n_total_samples*balance_ratio - n_samples)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "suspended-field",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([82, 18], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal_balancing_num_instance_multiclass(y, balance_ratio):\n",
    "    \n",
    "    oversampling_counts = {}\n",
    "    n_samples = y.shape[0]\n",
    "    n_classes = y.shape[1]\n",
    "    \n",
    "    for col in y.columns:\n",
    "        oversampling_counts[col] = cal_balancing_num_instance_binary(y[col].sum(), n_samples, balance_ratio)\n",
    "    \n",
    "    return oversampling_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9c4cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    if norm1 == 0:\n",
    "        norm1 += 0.00001\n",
    "    if norm2 == 0:\n",
    "        norm2 += 0.00001   \n",
    "    return np.dot(vec1, vec2)/(norm1*norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "586c624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski_similarity(u, v, p=2):\n",
    "    # minkowski distance is a distance measure but we need a similarity function\n",
    "    if p <= 0:\n",
    "        raise ValueError(\"p must be greater than 0\")\n",
    "    u_v = u - v\n",
    "    dist = np.linalg.norm(u_v, ord=p)\n",
    "    if dist == 0:\n",
    "        dist += 0.0001\n",
    "        \n",
    "    return 1/dist #converting a distance to similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "23827acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(vec1, vec2, sim_type='cosine'):\n",
    "    \n",
    "    if sim_type == 'cosine':\n",
    "        similarity = cosine_similarity(vec1, vec2)\n",
    "    if sim_type == 'euclidean':\n",
    "        similarity = minkowski_similarity(vec1, vec2, 2)\n",
    "    if sim_type == 'manhattan':\n",
    "        similarity = minkowski_similarity(vec1, vec2, 1)\n",
    "    if sim_type == 'chebychev ':\n",
    "        similarity = minkowski_similarity(vec1, vec2, np.inf)\n",
    "    if sim_type.startswith('minkowski'):\n",
    "        similarity = minkowski_similarity(vec1, vec2, int(sim_type[-1]))\n",
    "        \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e466b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_within_class_similarity(vecs, sim_type):\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for i,j in list(combinations(vecs.index, 2)):\n",
    "        similarities.append(vector_similarity(vecs.loc[i], vecs.loc[j], sim_type))    \n",
    "        # similarities[(i, j)] = vector_similarity(vecs.loc[i], vecs.loc[j])\n",
    "            \n",
    "    try:\n",
    "        avg_similarity = sum(similarities)/len(similarities)\n",
    "    except AssertionErrors:\n",
    "        print('Error occured')\n",
    "        \n",
    "    return avg_similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "legal-barrier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!\n",
    "def oversample_dataset(num_of_new_instances, X_labeled, y_labeled, X_unlabeled, y_unlabeled):\n",
    "    \n",
    "    for col_name, num_instance in num_of_new_instances.items():\n",
    "        new_instances = find_new_instances(col_name, num_instance)\n",
    "    \n",
    "    add new instances to X_labeled (and y_labeled for test case)\n",
    "    remove new instances from X_unlabeled (and y_unlabeled for test case)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c008f16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e324a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "framed-george",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e103c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import preprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "import torch\n",
    "from sentence_transformers import util\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8c4c34",
   "metadata": {},
   "source": [
    "### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dfa7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_ratio = 0.5\n",
    "majority_path = r'C:\\Users\\IsmailKaraman\\workspace\\data\\privacy_policy_data\\OPP-115_v2\\majority.csv'\n",
    "\n",
    "col_names = ['Data Retention', 'Data Security', 'Do Not Track', 'First Party Collection/Use', \n",
    "             'International and Specific Audiences',       'Introductory/Generic', 'Policy Change', \n",
    "             'Practice not covered', 'Privacy contact information', 'Third Party Sharing/Collection',\n",
    "             'User Access, Edit and Deletion', 'User Choice/Control']\n",
    "\n",
    "sub_col_names = ['Data Security', 'User Access, Edit and Deletion', 'Policy Change']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ade05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data\n",
    "df = pd.read_csv(majority_path)\n",
    "# -------------------------------------------------------------------------\n",
    "# creating a toy dataset to provide efficiency\n",
    "toy_df = df[(df[col_names].sum(axis=1)==df[sub_col_names].sum(axis=1))].sample(100)\n",
    "# -------------------------------------------------------------------------\n",
    "X = toy_df['text']\n",
    "y = toy_df[sub_col_names]\n",
    "# -------------------------------------------------------------------------\n",
    "# reading from a pickle instead of applying vectorization\n",
    "'''\n",
    "X_num = X.apply(vectorize_data)\n",
    "import pickle\n",
    "with open('X_num.p', 'wb') as f:\n",
    "    pickle.dump(X_num, f)     \n",
    "'''\n",
    "with open('X_num.p', 'rb') as f:\n",
    "    X_num = pickle.load(f)\n",
    "# ------------------------------------------------------------------------\n",
    "# splitting train(labeled-unlabeled)-test\n",
    "# X_num = X.apply(vectorize_data) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_num, y, test_size=0.2, random_state=0, stratify=y)\n",
    "X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(X_train, y_train, test_size=0.75, \n",
    "                                                                  stratify=y_train, random_state=2)\n",
    "# ------------------------------------------------------------------------\n",
    "# an initial classifier to see results before applying our method\n",
    "classifier(X_labeled.values, y_labeled, X_test, y_test)\n",
    "# ------------------------------------------------------------------------\n",
    "# calculation number of instances to balance dataset\n",
    "balance_ratio = 0.5\n",
    "num_of_new_instances = cal_balancing_num_instance_multiclass(y_labeled, balance_ratio)\n",
    "# ------------------------------------------------------------------------\n",
    "# oversampling dataset using unlabeled data with the given ratios\n",
    "X_labeled, y_labeled, X_unlabeled, y_unlabeled = oversample_dataset(num_of_new_instances, \n",
    "                                                                    X_labeled, y_labeled, X_unlabeled, y_unlabeled)\n",
    "# ------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab5b1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-leisure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-gnome",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-klein",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-niger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e6f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "all_words = words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1758031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_5len = [word.lower() for word in all_words if len(word)==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-missouri",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for word in words_5len:\n",
    "    if 'h' in word and 'k' in word and 'n' in word:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-behalf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for word in words_5len:\n",
    "    if word.startswith('se') and 'r' in word:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_0 = ''\n",
    "letter_1 = ''\n",
    "letter_2 = 'a'\n",
    "letter_3 = ''\n",
    "letter_4 = ''\n",
    "\n",
    "exist_letters = 'acs'\n",
    "banned_letters = 'trdefou'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [word for word in words_5len for e in exist_letters if e in word]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b866aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [word for word in filtered for b in banned_letters if b in word]\n",
    "filtered = [word for word in filtered if letter_0 and word[0]==letter_0]\n",
    "filtered = [word for word in filtered if letter_1 and word[0]==letter_1]\n",
    "filtered = [word for word in filtered if letter_2 and word[0]==letter_2]\n",
    "filtered = [word for word in filtered if letter_3 and word[0]==letter_3]\n",
    "filtered = [word for word in filtered if letter_4 and word[0]==letter_4]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "if letter_2:\n",
    "    print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ebbe7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for word in words_5len:\n",
    "    if 'o' in word and 'u' in word and 'a' not in word and 'i' not in word and 'd' not in word:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b7269e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
