{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8edd5e50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utilities\n",
    "import preprocess\n",
    "import parameters\n",
    "\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sentence_transformers import util, SentenceTransformer\n",
    "from sklearn.metrics import hamming_loss, accuracy_score, f1_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "095e9601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-packing",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f677899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing algorithm parameters\n",
    "sim_type = parameters.sim_type\n",
    "random_state = parameters.random_state\n",
    "test_size = parameters.test_size\n",
    "\n",
    "# doe\n",
    "balance_ratio = parameters.balance_ratio\n",
    "sim_calculation_type = parameters.sim_calculation_type\n",
    "\n",
    "success_metric = parameters.success_metric\n",
    "embedding_method = parameters.embedding_method\n",
    "data_paths = parameters.data_paths\n",
    "X_num_paths = parameters.X_num_paths\n",
    "unlabeled_ratios = parameters.unlabeled_ratios\n",
    "\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hundred-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier_object = LinearSVC(class_weight='balanced')\n",
    "classifier_object = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7375efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(X_train, y_train, test_size=unlabeled_ratios[data], \n",
    "                                                                  random_state=random_state)\n",
    "    \n",
    "    return X_labeled, y_labeled, X_unlabeled, y_unlabeled, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae093411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_KFold(X, cv):\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=cv, random_state=random_state, shuffle=True)\n",
    "    \n",
    "    splits = []\n",
    "    for train_idx, test_idx in kf.split(X.index):\n",
    "        \n",
    "        labeled_idx, unlabeled_idx = train_test_split(train_idx, test_size=unlabeled_ratios[data], random_state=random_state)\n",
    "        \n",
    "        splits.append((labeled_idx, unlabeled_idx, test_idx))\n",
    "        \n",
    "    return splits    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f90eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data):\n",
    "    # reading data\n",
    "    df = utilities.read_data(data_paths[data])\n",
    "    # X = df['text'].apply(preprocess.preprocess_text)\n",
    "    y = df.drop(['text'], axis=1)\n",
    "    # ------------------------------------------------------------------------------------------------------------------------------\n",
    "    # reading from a pickle instead of applying vectorization\n",
    "    # X_num = utilities.vectorize_data(X, embedding_method)\n",
    "    # X_num = pd.Series([np.squeeze(i) for i in X_num])\n",
    "    X = pd.read_pickle(X_num_paths[data])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-george",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "british-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data, balance_ratio, sim_calculation_type, single_metric, oversampler_version, batch_size, n_iter=None):\n",
    "    \n",
    "    print('*'*100)\n",
    "    print('\\x1b[1;31m'+data+'\\x1b[0m')\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_num, y, test_size=test_size, random_state=random_state)\n",
    "    X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(X_train, y_train, test_size=unlabeled_ratios[data], \n",
    "                                                                  random_state=random_state)\n",
    "    \n",
    "    shape_before = X_labeled.shape[0]\n",
    "    print(X_labeled.shape, X_unlabeled.shape, X_test.shape)\n",
    "    s_metric = utilities.multilabel_classifier(np.vstack(X_labeled), y_labeled, np.vstack(X_test), y_test, \n",
    "                                               success_metric=success_metric,\n",
    "                                               classifier_object = classifier_object, \n",
    "                                               print_results=True)\n",
    "    # -----------------------------------------------------------------------------------------------------------------------------\n",
    "    # calculation number of instances to balance dataset\n",
    "    num_of_new_instances = utilities.calculate_balancing_num_instance_multiclass(y_labeled, balance_ratio, \n",
    "                                                                                 calculation_type='metric_based', \n",
    "                                                                                 s_metrics=s_metric)\n",
    "    # -----------------------------------------------------------------------------------------------------------------------------\n",
    "    # oversampling dataset using unlabeled data with the given ratios\n",
    "    # print('num_of_new_instances : ',num_of_new_instances)\n",
    "    if oversampler_version == 'v1':\n",
    "        validation, X_labeled, y_labeled, X_unlabeled, y_unlabeled = utilities.oversample_dataset_v1(\n",
    "                                                                        num_of_new_instances, X_labeled, y_labeled, \n",
    "                                                                        X_unlabeled, y_unlabeled, X_test, y_test, \n",
    "                                                                        sim_calculation_type=sim_calculation_type,\n",
    "                                                                        batch_size=batch_size)\n",
    "    elif oversampler_version == 'v2':\n",
    "        validation, X_labeled, y_labeled, X_unlabeled, y_unlabeled = utilities.oversample_dataset_v2(\n",
    "                                                                        num_of_new_instances, X_labeled, y_labeled, \n",
    "                                                                        X_unlabeled, y_unlabeled, X_test, y_test, \n",
    "                                                                        sim_calculation_type=sim_calculation_type,\n",
    "                                                                        batch_size=batch_size)\n",
    "    elif oversampler_version == 'v3':\n",
    "        validation, X_labeled, y_labeled, X_unlabeled, y_unlabeled = utilities.oversample_dataset_v3(\n",
    "                                                                        num_of_new_instances, X_labeled, y_labeled, \n",
    "                                                                        X_unlabeled, y_unlabeled, X_test, y_test, \n",
    "                                                                        sim_calculation_type=sim_calculation_type,\n",
    "                                                                        batch_size=batch_size, \n",
    "                                                                        n_iter=n_iter, \n",
    "                                                                        single_score=single_metric)\n",
    "    elif oversampler_version == 'v4':\n",
    "        validation, X_labeled, y_labeled, X_unlabeled, y_unlabeled = utilities.oversample_dataset_v4(\n",
    "                                                                     num_of_new_instances, \n",
    "                                                                     X_labeled, y_labeled, \n",
    "                                                                     X_unlabeled, y_unlabeled, \n",
    "                                                                     X_test, y_test, \n",
    "                                                                     sim_calculation_type=sim_calculation_type, \n",
    "                                                                     batch_size=batch_size, \n",
    "                                                                     n_iter=n_iter,\n",
    "                                                                     balance_ratio=balance_ratio,\n",
    "                                                                     success_metric=success_metric,\n",
    "                                                                     single_score=single_metric)\n",
    "    # -----------------------------------------------------------------------------------------------------------------------------\n",
    "    # check if the result gets better\n",
    "    shape_after = X_labeled.shape[0]\n",
    "    s_metric = utilities.multilabel_classifier(np.vstack(X_labeled), y_labeled, np.vstack(X_test), y_test, \n",
    "                                               success_metric=success_metric,\n",
    "                                               classifier_object = classifier_object, \n",
    "                                               print_results=True)\n",
    "    # comparing the found labels and ground truth\n",
    "    y_true, y_pred = [], []\n",
    "    for _, _, _, y_t, y_p in validation:\n",
    "        y_true.append(list(y_t.values))\n",
    "        y_pred.append(list(y_p.values()))\n",
    "    \n",
    "    acc = 1-hamming_loss(y_true, y_pred)\n",
    "    emr = accuracy_score(y_true, y_pred)  \n",
    "    print('-'*30)\n",
    "    print(f'Shape: before {shape_before}, after {shape_after} : {shape_after-shape_before} instances added...')\n",
    "    print(f'Exact match ratio : {emr:.2f} ')\n",
    "    print(f'Accuracy          : {acc:.2f} ')\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e6d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_CV(data, balance_ratio, sim_calculation_type, single_metric, oversampler_version, batch_size, n_iter=None):\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    X, y = read_data(data)\n",
    "\n",
    "    splits = split_data_KFold(X, 5)\n",
    "\n",
    "    for labeled_idx, unlabeled_idx, test_idx in splits:\n",
    "\n",
    "        X_labeled = X.loc[labeled_idx]\n",
    "        y_labeled = y.loc[labeled_idx]\n",
    "        X_unlabeled = X.loc[unlabeled_idx]\n",
    "        y_unlabeled = y.loc[unlabeled_idx]\n",
    "        X_test = X.loc[test_idx]\n",
    "        y_test = y.loc[test_idx]\n",
    "    \n",
    "    \n",
    "        shape_before = X_labeled.shape[0]\n",
    "        print(X_labeled.shape, X_unlabeled.shape, X_test.shape)\n",
    "\n",
    "        s_metric = utilities.multilabel_classifier(np.vstack(X_labeled), y_labeled, np.vstack(X_test), y_test, \n",
    "                                                   success_metric=success_metric,\n",
    "                                                   classifier_object = classifier_object, \n",
    "                                                   print_results=True)\n",
    "        # -----------------------------------------------------------------------------------------------------------------------------\n",
    "        # calculation number of instances to balance dataset\n",
    "        num_of_new_instances = utilities.calculate_balancing_num_instance_multiclass(y_labeled, balance_ratio, \n",
    "                                                                                     calculation_type='metric_based', \n",
    "                                                                                     s_metrics=s_metric)\n",
    "        # -----------------------------------------------------------------------------------------------------------------------------\n",
    "        # oversampling dataset using unlabeled data with the given ratios\n",
    "        # print('num_of_new_instances : ',num_of_new_instances)\n",
    "        if oversampler_version == 'v1':\n",
    "            validation, X_labeled, y_labeled, X_unlabeled, y_unlabeled = utilities.oversample_dataset_v1(\n",
    "                                                                            num_of_new_instances, X_labeled, y_labeled, \n",
    "                                                                            X_unlabeled, y_unlabeled, X_test, y_test, \n",
    "                                                                            sim_calculation_type=sim_calculation_type,\n",
    "                                                                            batch_size=batch_size)\n",
    "        elif oversampler_version == 'v2':\n",
    "            validation, X_labeled, y_labeled, X_unlabeled, y_unlabeled = utilities.oversample_dataset_v2(\n",
    "                                                                            num_of_new_instances, X_labeled, y_labeled, \n",
    "                                                                            X_unlabeled, y_unlabeled, X_test, y_test, \n",
    "                                                                            sim_calculation_type=sim_calculation_type,\n",
    "                                                                            batch_size=batch_size)\n",
    "        elif oversampler_version == 'v3':\n",
    "            validation, X_labeled, y_labeled, X_unlabeled, y_unlabeled = utilities.oversample_dataset_v3(\n",
    "                                                                            num_of_new_instances, X_labeled, y_labeled, \n",
    "                                                                            X_unlabeled, y_unlabeled, X_test, y_test, \n",
    "                                                                            sim_calculation_type=sim_calculation_type,\n",
    "                                                                            batch_size=batch_size, \n",
    "                                                                            n_iter=n_iter, \n",
    "                                                                            single_score=single_metric)\n",
    "        elif oversampler_version == 'v4':\n",
    "            validation, X_labeled, y_labeled, X_unlabeled, y_unlabeled = utilities.oversample_dataset_v4(\n",
    "                                                                         num_of_new_instances, \n",
    "                                                                         X_labeled, y_labeled, \n",
    "                                                                         X_unlabeled, y_unlabeled, \n",
    "                                                                         X_test, y_test, \n",
    "                                                                         sim_calculation_type=sim_calculation_type, \n",
    "                                                                         batch_size=batch_size, \n",
    "                                                                         n_iter=n_iter,\n",
    "                                                                         balance_ratio=balance_ratio,\n",
    "                                                                         success_metric=success_metric,\n",
    "                                                                         single_score=single_metric)\n",
    "        # -----------------------------------------------------------------------------------------------------------------------------\n",
    "        # check if the result gets better\n",
    "        shape_after = X_labeled.shape[0]\n",
    "        s_metric = utilities.multilabel_classifier(np.vstack(X_labeled), y_labeled, np.vstack(X_test), y_test, \n",
    "                                                   success_metric=success_metric,\n",
    "                                                   classifier_object = classifier_object, \n",
    "                                                   print_results=True)\n",
    "        # comparing the found labels and ground truth\n",
    "        y_true, y_pred = [], []\n",
    "        for _, _, _, y_t, y_p in validation:\n",
    "            y_true.append(list(y_t.values))\n",
    "            y_pred.append(list(y_p.values()))\n",
    "\n",
    "        acc = 1-hamming_loss(y_true, y_pred)\n",
    "        emr = accuracy_score(y_true, y_pred)  \n",
    "        print('-'*30)\n",
    "        print(f'Shape: before {shape_before}, after {shape_after} : {shape_after-shape_before} instances added...')\n",
    "        print(f'Exact match ratio : {emr:.2f} ')\n",
    "        print(f'Accuracy          : {acc:.2f} ')\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print('-'*30)\n",
    "    \n",
    "    \n",
    "        shape_after, shape_before\n",
    "        acr, emr\n",
    "        old_metric, new metric\n",
    "        scores.add\n",
    "        \n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da807fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_CV(data, ):\n",
    "    \n",
    "    print('*'*100)\n",
    "    print('\\x1b[1;31m'+data+'\\x1b[0m')\n",
    "    \n",
    "    result = run_CV(data, balance_ratio, sim_calculation_type, single_metric, oversampler_version, batch_size, n_iter=None)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58e1b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'opp115'\n",
    "balance_ratio = 0.5\n",
    "sim_calculation_type = 'average'\n",
    "single_metric = 'coverage'\n",
    "oversampler_version = 'v1'\n",
    "batch_size = 1\n",
    "n_iter = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eefcc08e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "\u001b[1;31mopp115\u001b[0m\n",
      "(135,) (2584,) (680,)\n",
      "\u001b[1mMultilabel Classifier Results\u001b[0m\n",
      "\u001b[1mLogisticRegression\u001b[0m\n",
      "------------------------------\n",
      "Hamming Loss\n",
      "Training : 0.05\n",
      "Test     : 0.08\n",
      "Exact Match Ratio\n",
      "Training : 0.55\n",
      "Test     : 0.39\n",
      "Macro F1-Score\n",
      "Training : 0.74\n",
      "Test     : 0.64\n",
      "Coverage Error\n",
      "Training : 1.46\n",
      "Test     : 2.06\n",
      "Ranking Loss Error\n",
      "Training : 0.02\n",
      "Test     : 0.07\n",
      "------------------------------\n",
      "\u001b[1mClassification Report\u001b[0m\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                      Data Retention       0.35      0.74      0.47        19\n",
      "                       Data Security       0.70      0.82      0.76        51\n",
      "                        Do Not Track       0.65      0.92      0.76        12\n",
      "          First Party Collection/Use       0.67      0.72      0.70       218\n",
      "International and Specific Audiences       0.73      0.84      0.78        55\n",
      "                Introductory/Generic       0.44      0.73      0.55        75\n",
      "                       Policy Change       0.65      0.92      0.76        24\n",
      "                Practice not covered       0.40      0.72      0.52        32\n",
      "         Privacy contact information       0.52      0.83      0.64        36\n",
      "      Third Party Sharing/Collection       0.82      0.76      0.79       182\n",
      "      User Access, Edit and Deletion       0.27      0.78      0.40        27\n",
      "                 User Choice/Control       0.55      0.71      0.62        79\n",
      "\n",
      "                           micro avg       0.59      0.76      0.67       810\n",
      "                           macro avg       0.56      0.79      0.64       810\n",
      "                        weighted avg       0.64      0.76      0.68       810\n",
      "                         samples avg       0.65      0.80      0.69       810\n",
      "\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n",
      "Shapes --------------\n",
      "(294,) (2180,)\n",
      "\u001b[1mMultilabel Classifier Results\u001b[0m\n",
      "\u001b[1mLogisticRegression\u001b[0m\n",
      "------------------------------\n",
      "Hamming Loss\n",
      "Training : 0.06\n",
      "Test     : 0.08\n",
      "Exact Match Ratio\n",
      "Training : 0.46\n",
      "Test     : 0.33\n",
      "Macro F1-Score\n",
      "Training : 0.76\n",
      "Test     : 0.64\n",
      "Coverage Error\n",
      "Training : 1.48\n",
      "Test     : 2.07\n",
      "Ranking Loss Error\n",
      "Training : 0.02\n",
      "Test     : 0.07\n",
      "------------------------------\n",
      "\u001b[1mClassification Report\u001b[0m\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                      Data Retention       0.33      0.74      0.46        19\n",
      "                       Data Security       0.70      0.84      0.77        51\n",
      "                        Do Not Track       0.61      0.92      0.73        12\n",
      "          First Party Collection/Use       0.57      0.80      0.67       218\n",
      "International and Specific Audiences       0.72      0.85      0.78        55\n",
      "                Introductory/Generic       0.40      0.77      0.53        75\n",
      "                       Policy Change       0.61      0.92      0.73        24\n",
      "                Practice not covered       0.37      0.72      0.49        32\n",
      "         Privacy contact information       0.64      0.81      0.72        36\n",
      "      Third Party Sharing/Collection       0.60      0.77      0.67       182\n",
      "      User Access, Edit and Deletion       0.42      0.70      0.53        27\n",
      "                 User Choice/Control       0.64      0.66      0.65        79\n",
      "\n",
      "                           micro avg       0.56      0.78      0.65       810\n",
      "                           macro avg       0.55      0.79      0.64       810\n",
      "                        weighted avg       0.57      0.78      0.66       810\n",
      "                         samples avg       0.61      0.81      0.67       810\n",
      "\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n",
      "------------------------------\n",
      "Shape: before 135, after 294 : 159 instances added...\n",
      "Exact match ratio : 0.44 \n",
      "Accuracy          : 0.91 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       1.00      0.04      0.08        24\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.94      0.94      0.94        16\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.95      0.64      0.76        33\n",
      "           9       0.27      0.83      0.41        18\n",
      "          10       0.57      0.89      0.70        44\n",
      "          11       0.51      0.66      0.57        44\n",
      "\n",
      "   micro avg       0.55      0.62      0.58       195\n",
      "   macro avg       0.35      0.33      0.29       195\n",
      "weighted avg       0.63      0.62      0.54       195\n",
      " samples avg       0.64      0.64      0.62       195\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "main(data, balance_ratio, sim_calculation_type, single_metric, oversampler_version, batch_size, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8f23a2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "\u001b[1;31mopp115\u001b[0m\n",
      "(135,) (2584,) (680,)\n",
      "\u001b[1mMultilabel Classifier Results\u001b[0m\n",
      "\u001b[1mLogisticRegression\u001b[0m\n",
      "------------------------------\n",
      "Hamming Loss\n",
      "Training : 0.05\n",
      "Test     : 0.08\n",
      "Exact Match Ratio\n",
      "Training : 0.55\n",
      "Test     : 0.39\n",
      "Macro F1-Score\n",
      "Training : 0.74\n",
      "Test     : 0.64\n",
      "Coverage Error\n",
      "Training : 1.46\n",
      "Test     : 2.06\n",
      "Ranking Loss Error\n",
      "Training : 0.02\n",
      "Test     : 0.07\n",
      "------------------------------\n",
      "\u001b[1mClassification Report\u001b[0m\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                      Data Retention       0.35      0.74      0.47        19\n",
      "                       Data Security       0.70      0.82      0.76        51\n",
      "                        Do Not Track       0.65      0.92      0.76        12\n",
      "          First Party Collection/Use       0.67      0.72      0.70       218\n",
      "International and Specific Audiences       0.73      0.84      0.78        55\n",
      "                Introductory/Generic       0.44      0.73      0.55        75\n",
      "                       Policy Change       0.65      0.92      0.76        24\n",
      "                Practice not covered       0.40      0.72      0.52        32\n",
      "         Privacy contact information       0.52      0.83      0.64        36\n",
      "      Third Party Sharing/Collection       0.82      0.76      0.79       182\n",
      "      User Access, Edit and Deletion       0.27      0.78      0.40        27\n",
      "                 User Choice/Control       0.55      0.71      0.62        79\n",
      "\n",
      "                           micro avg       0.59      0.76      0.67       810\n",
      "                           macro avg       0.56      0.79      0.64       810\n",
      "                        weighted avg       0.64      0.76      0.68       810\n",
      "                         samples avg       0.65      0.80      0.69       810\n",
      "\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n",
      "Shapes --------------\n",
      "(294,) (2180,)\n",
      "\u001b[1mMultilabel Classifier Results\u001b[0m\n",
      "\u001b[1mLogisticRegression\u001b[0m\n",
      "------------------------------\n",
      "Hamming Loss\n",
      "Training : 0.06\n",
      "Test     : 0.08\n",
      "Exact Match Ratio\n",
      "Training : 0.46\n",
      "Test     : 0.33\n",
      "Macro F1-Score\n",
      "Training : 0.76\n",
      "Test     : 0.64\n",
      "Coverage Error\n",
      "Training : 1.48\n",
      "Test     : 2.07\n",
      "Ranking Loss Error\n",
      "Training : 0.02\n",
      "Test     : 0.07\n",
      "------------------------------\n",
      "\u001b[1mClassification Report\u001b[0m\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                      Data Retention       0.33      0.74      0.46        19\n",
      "                       Data Security       0.70      0.84      0.77        51\n",
      "                        Do Not Track       0.61      0.92      0.73        12\n",
      "          First Party Collection/Use       0.57      0.80      0.67       218\n",
      "International and Specific Audiences       0.72      0.85      0.78        55\n",
      "                Introductory/Generic       0.40      0.77      0.53        75\n",
      "                       Policy Change       0.61      0.92      0.73        24\n",
      "                Practice not covered       0.37      0.72      0.49        32\n",
      "         Privacy contact information       0.64      0.81      0.72        36\n",
      "      Third Party Sharing/Collection       0.60      0.77      0.67       182\n",
      "      User Access, Edit and Deletion       0.42      0.70      0.53        27\n",
      "                 User Choice/Control       0.64      0.66      0.65        79\n",
      "\n",
      "                           micro avg       0.56      0.78      0.65       810\n",
      "                           macro avg       0.55      0.79      0.64       810\n",
      "                        weighted avg       0.57      0.78      0.66       810\n",
      "                         samples avg       0.61      0.81      0.67       810\n",
      "\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n",
      "------------------------------\n",
      "Shape: before 135, after 294 : 159 instances added...\n",
      "Exact match ratio : 0.44 \n",
      "Accuracy          : 0.91 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       1.00      0.04      0.08        24\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.94      0.94      0.94        16\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.95      0.64      0.76        33\n",
      "           9       0.27      0.83      0.41        18\n",
      "          10       0.57      0.89      0.70        44\n",
      "          11       0.51      0.66      0.57        44\n",
      "\n",
      "   micro avg       0.55      0.62      0.58       195\n",
      "   macro avg       0.35      0.33      0.29       195\n",
      "weighted avg       0.63      0.62      0.54       195\n",
      " samples avg       0.64      0.64      0.62       195\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "main(data, balance_ratio, sim_calculation_type, single_metric, oversampler_version, batch_size, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f314b31",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ISMAIL~1\\AppData\\Local\\Temp/ipykernel_19872/3957423419.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9116113",
   "metadata": {},
   "outputs": [],
   "source": [
    "main('opp115', balance_ratio, sim_calculation_type, single_metric, 'v1', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826841e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "main('opp115', balance_ratio, sim_calculation_type,  single_metric, 'v2', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d22560e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "main('opp115', balance_ratio, sim_calculation_type,  'coverage', 'v3', batch_size, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453970a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "main('opp115', balance_ratio, sim_calculation_type, 'coverage', 'v4', batch_size, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27227a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0103f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'opp115'\n",
    "balance_ratio = 0.5\n",
    "sim_calculation_type = 'average'\n",
    "single_metric = 'coverage'\n",
    "oversampler_version = 'v1'\n",
    "batch_size = 1\n",
    "n_iter = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8110af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "'data' : ['opp115', 'ohsumed', 'reuters'],\n",
    "'balance_ratio' : [0.2, 0.5],\n",
    "'sim_calculation_type' : ['average', 'safe_interval'],\n",
    "'single_metric' : ['accuracy', 'f1_score', 'coverage', 'label_ranking', 'roc_auc_score', 'log_loss', 'average_precision',\n",
    "                   'brier_loss', 'hamming_loss', 'precision', 'recall', 'zero_one_loss', 'label_ranking_average_precision'],\n",
    "'oversampler_version' : ['v1', 'v2', 'v3', 'v4'],\n",
    "'batch_size' : [1,3,5],\n",
    "'n_iter' : [100, 1000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f2e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "replication_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "daf9012f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['opp115', 'ohsumed', 'reuters']\n",
      "[0.2, 0.5]\n",
      "['average', 'safe_interval']\n",
      "['accuracy', 'f1_score', 'coverage', 'label_ranking', 'roc_auc_score', 'log_loss', 'average_precision', 'brier_loss', 'hamming_loss', 'precision', 'recall', 'zero_one_loss', 'label_ranking_average_precision']\n",
      "['v1', 'v2', 'v3', 'v4']\n",
      "[1, 3, 5]\n",
      "[100, 1000]\n"
     ]
    }
   ],
   "source": [
    "for data in parameters['data']:\n",
    "    for balance_ratio in parameters['balance_ratio']:\n",
    "        for sim_calculation_type in parameters['sim_calculation_type']:\n",
    "            for single_metric in parameters['single_metric']:\n",
    "                for oversampler_version in parameters['oversampler_version']:\n",
    "                    for batch_size in parameters['batch_size']:\n",
    "                        for n_iter in parameters['n_iter']:\n",
    "                            \n",
    "                            results = []\n",
    "                            param_list = [data, balance_ratio, sim_calculation_type, single_metric, oversampler_version,\n",
    "                                         batch_size, n_iter]\n",
    "                            \n",
    "                            for i in range(replication_size):\n",
    "                                results.append(main(data, balance_ratio, sim_calculation_type, single_metric, \n",
    "                                                    oversampler_version, batch_size, n_iter))\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba811f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_new_instances = {'a':20, 'b':30, 'c':50}\n",
    "n_iter = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5252cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter_dist = {k:int(n_iter*v/sum(num_of_new_instances.values())) for k,v in num_of_new_instances.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03052345",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "main('opp115', embedding_method, classifier_object, sim_type, sim_calculation_type, success_metric, 'label-ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88df929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab2dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling methods\n",
    "\n",
    "oversample_dataset_v2(num_of_new_instances, X_labeled, y_labeled, X_unlabeled, y_unlabeled, X_test, y_test, sim_calculation_type, batch_size)\n",
    "oversample_dataset_v3(num_of_new_instances, X_labeled, y_labeled, X_unlabeled, y_unlabeled, X_test, y_test, sim_calculation_type, batch_size, n_iter)\n",
    "oversample_dataset_v4(num_of_new_instances, X_labeled, y_labeled, X_unlabeled, y_unlabeled, X_test, y_test, sim_calculation_type, batch_size, n_iter, balance_ratio, success_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-socket",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data in data_paths.keys():\n",
    "    main(data, embedding_method, classifier_object, sim_type, sim_calculation_type, success_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f970f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09141a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9a2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b4bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utilities.read_data(data_paths[data])\n",
    "X = df['text'].apply(preprocess.preprocess_text)\n",
    "y = df.drop(['text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y[col] == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9841b3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
