{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "realistic-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flag = 'opp115'\n",
    "\n",
    "# ohsumed: 23986\n",
    "# opp115 3399\n",
    "# reuters 10788"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "important-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utilities\n",
    "import preprocess\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-packing",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hundred-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm parameters\n",
    "balance_ratio = 0.5\n",
    "random_state = 1\n",
    "threshold_factor = 1.5\n",
    "test_size = 0.2\n",
    "\n",
    "sim_type = 'cosine'\n",
    "embedding_method = 'distiluse-base-multilingual-cased-v1' # try different embeddings and find proper one\n",
    "\n",
    "np.random.seed(random_state)\n",
    "\n",
    "data_paths = {'opp115'   : r'C:\\Users\\IsmailKaraman\\workspace\\data\\privacy_policy_data\\OPP-115_v2\\majority.csv',\n",
    "              'ohsumed'  : r'C:\\Users\\IsmailKaraman\\workspace\\GitHub\\thesis\\data\\ohsumed.csv',\n",
    "              'reuters'  : r'C:\\Users\\IsmailKaraman\\workspace\\GitHub\\thesis\\data\\Reuters21578.csv'}\n",
    "\n",
    "unlabaled_ratios = {'opp115':0.75, 'ohsumed':0.95, 'reuters':0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "known-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-george",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "british-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data):\n",
    "    print('*'*60)\n",
    "    print(data)\n",
    "    # reading data\n",
    "    df = utilities.read_data(data_paths[data])\n",
    "    X = df['text'].apply(preprocess.preprocess_text)\n",
    "    y = df.drop(['text'], axis=1)\n",
    "    # ------------------------------------------------------------------------------------------------------------------------------\n",
    "    # reading from a pickle instead of applying vectorization\n",
    "    X_num = utilities.vectorize_data(X, embedding_method)\n",
    "    X_num = pd.Series([np.squeeze(i) for i in X_num])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_num, y, test_size=test_size, random_state=random_state)\n",
    "    X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(X_train, y_train, test_size=unlabaled_ratios[data], \n",
    "                                                                  random_state=random_state)\n",
    "    \n",
    "    print(X_labeled.shape, y_labeled.shape, X_unlabeled.shape, y_unlabeled.shape)\n",
    "    utilities.classifier(np.vstack(X_labeled), y_labeled, np.vstack(X_test), y_test)\n",
    "    #utilities.classifier(np.vstack(X_labeled.values), y_labeled, np.vstack(X_test.values), y_test)\n",
    "    # -----------------------------------------------------------------------------------------------------------------------------\n",
    "    # calculation number of instances to balance dataset\n",
    "    balance_ratio = 0.5\n",
    "    num_of_new_instances = utilities.calculate_balancing_num_instance_multiclass(y_labeled, balance_ratio)\n",
    "    # -----------------------------------------------------------------------------------------------------------------------------\n",
    "    # oversampling dataset using unlabeled data with the given ratios\n",
    "    validation, X_labeled, y_labeled, X_unlabeled, y_unlabeled = utilities.oversample_dataset(num_of_new_instances, \n",
    "                                                                  X_labeled, y_labeled, X_unlabeled, y_unlabeled, threshold_factor)\n",
    "    # -----------------------------------------------------------------------------------------------------------------------------\n",
    "    # check if the result gets better\n",
    "    print(X_labeled.shape, X_unlabeled.shape, X_test.shape)\n",
    "    utilities.classifier(np.vstack(X_labeled.values), y_labeled, np.vstack(X_test.values), y_test)\n",
    "    \n",
    "    compare_res = []\n",
    "    for _, value in validation.items():\n",
    "        col, _, _, y_true, y_pred = value\n",
    "        compare_res.append((list(y_true.values), list(y_pred.values())))\n",
    "        \n",
    "    emr = 0\n",
    "    accuracy = 0\n",
    "    for t, p in compare_res:\n",
    "        if t==p:\n",
    "            emr += 1\n",
    "        if t[0] == p[0]:\n",
    "            accuracy +=1\n",
    "        if t[1] == p[1]:\n",
    "            accuracy +=1\n",
    "        if t[2] == p[2]:\n",
    "            accuracy +=1\n",
    "    print('Metrics for the proposed algorithm ')    \n",
    "    print(f'Exact match ratio : {emr/len(compare_res):.2f} ')\n",
    "    print(f'Accuracy          : {accuracy/(len(compare_res)*3):.2f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "satisfactory-socket",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "opp115\n",
      "(679,) (679, 12) (2040,) (2040, 12)\n",
      "\u001b[1mLinearSVM results: \u001b[0m\n",
      "------------------------------\n",
      "hamLoss: 0.07\n",
      "Exact Match Ratio: 0.46\n",
      "------------------------------\n",
      "\u001b[1mClassification Report\u001b[0m\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                      Data Retention       0.11      0.23      0.15        13\n",
      "                       Data Security       0.69      0.88      0.77        40\n",
      "                        Do Not Track       0.86      1.00      0.92         6\n",
      "          First Party Collection/Use       0.73      0.88      0.80       230\n",
      "International and Specific Audiences       0.92      0.81      0.86        68\n",
      "                Introductory/Generic       0.50      0.70      0.59        76\n",
      "                       Policy Change       0.74      0.91      0.82        22\n",
      "                Practice not covered       0.18      0.33      0.24        24\n",
      "         Privacy contact information       0.54      0.68      0.60        40\n",
      "      Third Party Sharing/Collection       0.68      0.72      0.70       183\n",
      "      User Access, Edit and Deletion       0.62      0.64      0.63        28\n",
      "                 User Choice/Control       0.57      0.71      0.63        66\n",
      "\n",
      "                           micro avg       0.63      0.76      0.69       796\n",
      "                           macro avg       0.59      0.71      0.64       796\n",
      "                        weighted avg       0.66      0.76      0.70       796\n",
      "                         samples avg       0.68      0.79      0.70       796\n",
      "\n",
      "(1574,) (1145,) (680,)\n",
      "\u001b[1mLinearSVM results: \u001b[0m\n",
      "------------------------------\n",
      "hamLoss: 0.13\n",
      "Exact Match Ratio: 0.23\n",
      "------------------------------\n",
      "\u001b[1mClassification Report\u001b[0m\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "                      Data Retention       0.02      0.23      0.04        13\n",
      "                       Data Security       0.52      0.78      0.62        40\n",
      "                        Do Not Track       0.08      1.00      0.16         6\n",
      "          First Party Collection/Use       0.68      0.76      0.72       230\n",
      "International and Specific Audiences       0.66      0.69      0.68        68\n",
      "                Introductory/Generic       0.49      0.54      0.52        76\n",
      "                       Policy Change       0.28      0.95      0.44        22\n",
      "                Practice not covered       0.06      0.46      0.11        24\n",
      "         Privacy contact information       0.40      0.60      0.48        40\n",
      "      Third Party Sharing/Collection       0.68      0.58      0.63       183\n",
      "      User Access, Edit and Deletion       0.25      0.50      0.33        28\n",
      "                 User Choice/Control       0.46      0.70      0.56        66\n",
      "\n",
      "                           micro avg       0.41      0.66      0.51       796\n",
      "                           macro avg       0.38      0.65      0.44       796\n",
      "                        weighted avg       0.56      0.66      0.59       796\n",
      "                         samples avg       0.46      0.69      0.52       796\n",
      "\n",
      "Metrics for the proposed algorithm \n",
      "Exact match ratio : 0.18 \n",
      "Accuracy          : 0.84 \n",
      "************************************************************\n",
      "ohsumed\n",
      "(959,) (959, 15) (18229,) (18229, 15)\n",
      "\u001b[1mLinearSVM results: \u001b[0m\n",
      "------------------------------\n",
      "hamLoss: 0.11\n",
      "Exact Match Ratio: 0.19\n",
      "------------------------------\n",
      "\u001b[1mClassification Report\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         c01       0.41      0.65      0.50       542\n",
      "         c02       0.36      0.57      0.44       250\n",
      "         c05       0.36      0.64      0.46       339\n",
      "         c06       0.47      0.69      0.56       596\n",
      "         c08       0.60      0.73      0.66       559\n",
      "         c10       0.52      0.68      0.59       760\n",
      "         c11       0.55      0.66      0.60       215\n",
      "         c12       0.48      0.72      0.57       479\n",
      "         c13       0.46      0.72      0.57       305\n",
      "         c15       0.18      0.44      0.26       229\n",
      "         c16       0.26      0.43      0.33       210\n",
      "         c17       0.31      0.57      0.40       357\n",
      "         c18       0.55      0.62      0.59       385\n",
      "         c20       0.39      0.67      0.49       600\n",
      "         c21       0.45      0.62      0.53       604\n",
      "\n",
      "   micro avg       0.43      0.65      0.52      6430\n",
      "   macro avg       0.42      0.63      0.50      6430\n",
      "weighted avg       0.45      0.65      0.53      6430\n",
      " samples avg       0.46      0.67      0.52      6430\n",
      "\n",
      "(1599,) (17589,) (4798,)\n",
      "\u001b[1mLinearSVM results: \u001b[0m\n",
      "------------------------------\n",
      "hamLoss: 0.11\n",
      "Exact Match Ratio: 0.19\n",
      "------------------------------\n",
      "\u001b[1mClassification Report\u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         c01       0.40      0.63      0.49       542\n",
      "         c02       0.37      0.59      0.46       250\n",
      "         c05       0.40      0.63      0.49       339\n",
      "         c06       0.47      0.71      0.57       596\n",
      "         c08       0.61      0.72      0.66       559\n",
      "         c10       0.48      0.69      0.57       760\n",
      "         c11       0.57      0.65      0.60       215\n",
      "         c12       0.48      0.71      0.57       479\n",
      "         c13       0.46      0.73      0.57       305\n",
      "         c15       0.20      0.45      0.28       229\n",
      "         c16       0.26      0.40      0.32       210\n",
      "         c17       0.29      0.56      0.38       357\n",
      "         c18       0.68      0.59      0.63       385\n",
      "         c20       0.36      0.67      0.47       600\n",
      "         c21       0.42      0.61      0.50       604\n",
      "\n",
      "   micro avg       0.42      0.64      0.51      6430\n",
      "   macro avg       0.43      0.62      0.50      6430\n",
      "weighted avg       0.44      0.64      0.52      6430\n",
      " samples avg       0.47      0.67      0.52      6430\n",
      "\n",
      "Metrics for the proposed algorithm \n",
      "Exact match ratio : 0.49 \n",
      "Accuracy          : 0.94 \n",
      "************************************************************\n",
      "reuters\n",
      "(863,) (863, 93) (7767,) (7767, 93)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Multioutput target data is not supported with label binarization",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2d9c0804a2f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_paths\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-a8edb676e289>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_labeled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_labeled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_unlabeled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_unlabeled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mutilities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_labeled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_labeled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;31m#utilities.classifier(np.vstack(X_labeled.values), y_labeled, np.vstack(X_test.values), y_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# -----------------------------------------------------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\workspace\\GitHub\\thesis\\utilities.py\u001b[0m in \u001b[0;36mclassifier\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# Linear SVM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;31m# overall.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    458\u001b[0m             \u001b[0mShape\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mproblems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         \"\"\"\n\u001b[1;32m--> 460\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_type_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'multioutput'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_type_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m             raise ValueError(\"Multioutput target data is not supported with \"\n\u001b[0m\u001b[0;32m    432\u001b[0m                              \"label binarization\")\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Multioutput target data is not supported with label binarization"
     ]
    }
   ],
   "source": [
    "for data in data_paths.keys():\n",
    "    main(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f970f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c613fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0d91c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b43b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffddfbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e6f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "all_words = words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1758031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_5len = [word.lower() for word in all_words if len(word)==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "data_vecs = vectorizer.fit_transform(data_words).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-missouri",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for word in words_5len:\n",
    "    if 'h' in word and 'k' in word and 'n' in word:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "common_dictionary = Dictionary(data_words)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in data_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vecs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e227fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.special import kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-behalf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for word in words_5len:\n",
    "    if word.startswith('se') and 'r' in word:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_0 = ''\n",
    "letter_1 = ''\n",
    "letter_2 = 'a'\n",
    "letter_3 = ''\n",
    "letter_4 = ''\n",
    "\n",
    "exist_letters = 'acs'\n",
    "banned_letters = 'trdefou'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381168a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_divergence(p, q):\n",
    "        \"\"\" Compute KL divergence of two vectors, K(p || q).\"\"\"\n",
    "        return sum(p[x] * log((p[x]) / (q[x])) for x in range(len(p)) if p[x] != 0.0 or p[x] != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9933bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros, array\n",
    "from math import sqrt, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ed5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "jensenshannon(p, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [word for word in words_5len for e in exist_letters if e in word]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b866aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [word for word in filtered for b in banned_letters if b in word]\n",
    "filtered = [word for word in filtered if letter_0 and word[0]==letter_0]\n",
    "filtered = [word for word in filtered if letter_1 and word[0]==letter_1]\n",
    "filtered = [word for word in filtered if letter_2 and word[0]==letter_2]\n",
    "filtered = [word for word in filtered if letter_3 and word[0]==letter_3]\n",
    "filtered = [word for word in filtered if letter_4 and word[0]==letter_4]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b69d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSD(object):\n",
    "    def __init__(self):\n",
    "        self.log2 = log(2)\n",
    "\n",
    "\n",
    "    def KL_divergence(self, p, q):\n",
    "        \"\"\" Compute KL divergence of two vectors, K(p || q).\"\"\"\n",
    "        return sum(p[x] * log((p[x]) / (q[x])) for x in range(len(p)) if p[x] != 0.0 or p[x] != 0)\n",
    "\n",
    "    def Jensen_Shannon_divergence(self, p, q):\n",
    "        \"\"\" Returns the Jensen-Shannon divergence. \"\"\"\n",
    "        self.JSD = 0.0\n",
    "        weight = 0.5\n",
    "        average = zeros(len(p)) #Average\n",
    "        for x in range(len(p)):\n",
    "            average[x] = weight * p[x] + (1 - weight) * q[x]\n",
    "            self.JSD = (weight * self.KL_divergence(array(p), average)) + ((1 - weight) * self.KL_divergence(array(q), average))\n",
    "        return 1-(self.JSD/sqrt(2 * self.log2))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    J = JSD()\n",
    "    p = [1.0/10, 9.0/10, 0]\n",
    "    q = [0, 1.0/10, 9.0/10]\n",
    "    p = data_vecs[0]\n",
    "    q = data_vecs[1]\n",
    "    print(J.Jensen_Shannon_divergence(p, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "if letter_2:\n",
    "    print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ebbe7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for word in words_5len:\n",
    "    if 'o' in word and 'u' in word and 'a' not in word and 'i' not in word and 'd' not in word:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b7269e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa5e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aaecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9841b3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
