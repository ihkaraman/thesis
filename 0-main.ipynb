{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8edd5e50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utilities\n",
    "import preprocess\n",
    "import parameters\n",
    "\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sentence_transformers import util, SentenceTransformer\n",
    "from sklearn.metrics import hamming_loss, accuracy_score, f1_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "095e9601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-packing",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f677899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing algorithm parameters\n",
    "balance_ratio = parameters.balance_ratio\n",
    "random_state = parameters.random_state\n",
    "threshold_factor = parameters.threshold_factor\n",
    "test_size = parameters.test_size\n",
    "sim_calculation_type = parameters.sim_calculation_type\n",
    "sim_type = parameters.sim_type\n",
    "success_metric = parameters.success_metric\n",
    "embedding_method = parameters.embedding_method\n",
    "data_paths = parameters.data_paths\n",
    "unlabaled_ratios = parameters.unlabaled_ratios\n",
    "\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hundred-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier_object = LinearSVC(class_weight='balanced')\n",
    "classifier_object = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-george",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "british-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data, embedding_method, classifier_object, sim_type, sim_calculation_type, success_metric, \n",
    "         single_metric, oversampler_version):\n",
    "    print('*'*100)\n",
    "    print('\\x1b[1;31m'+data+'\\x1b[0m')\n",
    "    # reading data\n",
    "    df = utilities.read_data(data_paths[data])\n",
    "    X = df['text'].apply(preprocess.preprocess_text)\n",
    "    y = df.drop(['text'], axis=1)\n",
    "    # ------------------------------------------------------------------------------------------------------------------------------\n",
    "    # reading from a pickle instead of applying vectorization\n",
    "    # X_num = utilities.vectorize_data(X, embedding_method)\n",
    "    # X_num = pd.Series([np.squeeze(i) for i in X_num])\n",
    "    X_num = pd.read_pickle('X_num_opp115.p')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_num, y, test_size=test_size, random_state=random_state)\n",
    "    X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(X_train, y_train, test_size=unlabaled_ratios[data], \n",
    "                                                                  random_state=random_state)\n",
    "    \n",
    "    print(X_labeled.shape, X_unlabeled.shape, X_test.shape)\n",
    "    s_metric = utilities.multilabel_classifier(np.vstack(X_labeled), y_labeled, np.vstack(X_test), y_test, \n",
    "                                               success_metric=success_metric,\n",
    "                                               classifier_object = classifier_object, print_results=True)\n",
    "    # -----------------------------------------------------------------------------------------------------------------------------\n",
    "    # calculation number of instances to balance dataset\n",
    "    num_of_new_instances = utilities.calculate_balancing_num_instance_multiclass(y_labeled, balance_ratio, \n",
    "                                                                                 calculation_type='metric_based', \n",
    "                                                                                 s_metrics=s_metric)\n",
    "    # -----------------------------------------------------------------------------------------------------------------------------\n",
    "    # oversampling dataset using unlabeled data with the given ratios\n",
    "    print('num_of_new_instances : ',num_of_new_instances)\n",
    "    if oversampler_version == 'v1':\n",
    "        validation, X_labeled, y_labeled, X_unlabeled, y_unlabeled = utilities.oversample_dataset_v1(\n",
    "                                                                        num_of_new_instances, X_labeled, y_labeled, \n",
    "                                                                        X_unlabeled, y_unlabeled, X_test, y_test, \n",
    "                                                                        sim_calculation_type=sim_calculation_type,\n",
    "                                                                        batch_size=1)\n",
    "    elif oversampler_version == 'v2':\n",
    "        validation, X_labeled, y_labeled, X_unlabeled, y_unlabeled = utilities.oversample_dataset_v2(\n",
    "                                                                        num_of_new_instances, X_labeled, y_labeled, \n",
    "                                                                        X_unlabeled, y_unlabeled, X_test, y_test, \n",
    "                                                                        sim_calculation_type=sim_calculation_type,\n",
    "                                                                        batch_size=1)\n",
    "    elif oversampler_version == 'v3':\n",
    "        validation, X_labeled, y_labeled, X_unlabeled, y_unlabeled = utilities.oversample_dataset_v3(\n",
    "                                                                        num_of_new_instances, X_labeled, y_labeled, \n",
    "                                                                        X_unlabeled, y_unlabeled, X_test, y_test, \n",
    "                                                                        sim_calculation_type=sim_calculation_type,\n",
    "                                                                        batch_size=1, n_iter=1000, single_score=single_metric)\n",
    "    elif oversampler_version == 'v4':\n",
    "        validation, X_labeled, y_labeled, X_unlabeled, y_unlabeled = utilities.oversample_dataset_v4(\\\n",
    "                                                                     num_of_new_instances, \n",
    "                                                                     X_labeled, y_labeled, \n",
    "                                                                     X_unlabeled, y_unlabeled, \n",
    "                                                                     X_test, y_test, \\\n",
    "                                                                     sim_calculation_type=sim_calculation_type, \n",
    "                                                                     batch_size=1, \n",
    "                                                                     n_iter=1000,\n",
    "                                                                     balance_ratio=balance_ratio,\n",
    "                                                                     success_metric=success_metric,\n",
    "                                                                     single_score=single_metric)\n",
    "    # -----------------------------------------------------------------------------------------------------------------------------\n",
    "    # check if the result gets better\n",
    "    print(X_labeled.shape, X_unlabeled.shape, X_test.shape)\n",
    "    s_metric = utilities.multilabel_classifier(np.vstack(X_labeled), y_labeled, np.vstack(X_test), y_test, \n",
    "                                               success_metric=success_metric,\n",
    "                                               classifier_object = classifier_object, print_results=True)\n",
    "    # comparing the found labels and ground truth\n",
    "    y_true, y_pred = [], []\n",
    "    for _, _, _, y_t, y_p in validation:\n",
    "        y_true.append(list(y_t.values))\n",
    "        y_pred.append(list(y_p.values()))\n",
    "    \n",
    "    acc = 1-hamming_loss(y_true, y_pred)\n",
    "    emr = accuracy_score(y_true, y_pred)  \n",
    "    print('-'*30)\n",
    "    print(f'Exact match ratio : {emr:.2f} ')\n",
    "    print(f'Accuracy          : {acc:.2f} ')\n",
    "    print('-'*30)\n",
    "    \n",
    "    print('*'*100)\n",
    "    print('/'*100)\n",
    "    print('*'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168292d6",
   "metadata": {},
   "source": [
    "'accuracy'\n",
    "'f1_score'\n",
    "'coverage'\n",
    "'label_ranking'\n",
    "'roc_auc_score'\n",
    "'log_loss'\n",
    "'average_precision'\n",
    "'brier_loss'\n",
    "'hamming_loss'\n",
    "'precision'\n",
    "'recall'\n",
    "'zero_one_loss'\n",
    "'label_ranking_average_precision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30cc305c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "\u001b[1;31mopp115\u001b[0m\n",
      "(135,) (2584,) (680,)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'macro'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopp115\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim_calculation_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuccess_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcoverage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mv1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(data, embedding_method, classifier_object, sim_type, sim_calculation_type, success_metric, single_metric, oversampler_version)\u001b[0m\n\u001b[0;32m     15\u001b[0m X_labeled, X_unlabeled, y_labeled, y_unlabeled \u001b[38;5;241m=\u001b[39m train_test_split(X_train, y_train, test_size\u001b[38;5;241m=\u001b[39munlabaled_ratios[data], \n\u001b[0;32m     16\u001b[0m                                                               random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_labeled\u001b[38;5;241m.\u001b[39mshape, X_unlabeled\u001b[38;5;241m.\u001b[39mshape, X_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 19\u001b[0m s_metric \u001b[38;5;241m=\u001b[39m \u001b[43mutilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultilabel_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_labeled\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_labeled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43msuccess_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuccess_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mclassifier_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclassifier_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# calculation number of instances to balance dataset\u001b[39;00m\n\u001b[0;32m     24\u001b[0m num_of_new_instances \u001b[38;5;241m=\u001b[39m utilities\u001b[38;5;241m.\u001b[39mcalculate_balancing_num_instance_multiclass(y_labeled, balance_ratio, \n\u001b[0;32m     25\u001b[0m                                                                              calculation_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric_based\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     26\u001b[0m                                                                              s_metrics\u001b[38;5;241m=\u001b[39ms_metric)\n",
      "File \u001b[1;32m~\\workspace\\GitHub\\thesis\\utilities.py:213\u001b[0m, in \u001b[0;36mmultilabel_classifier\u001b[1;34m(X_train, y_train, X_test, y_test, success_metric, classifier_object, print_results)\u001b[0m\n\u001b[0;32m    211\u001b[0m clf_report_train \u001b[38;5;241m=\u001b[39m classification_report(y_train\u001b[38;5;241m.\u001b[39mvalues, train_preds, target_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(y_train\u001b[38;5;241m.\u001b[39mcolumns), output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \n\u001b[0;32m    212\u001b[0m clf_report_test \u001b[38;5;241m=\u001b[39m classification_report(y_test\u001b[38;5;241m.\u001b[39mvalues, test_preds, target_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(y_test\u001b[38;5;241m.\u001b[39mcolumns), output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \n\u001b[1;32m--> 213\u001b[0m f1_score_train \u001b[38;5;241m=\u001b[39m \u001b[43mclf_report_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric_weighting_type\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    214\u001b[0m f1_score_test \u001b[38;5;241m=\u001b[39m clf_report_test[metric_weighting_type][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    215\u001b[0m coverage_train \u001b[38;5;241m=\u001b[39m coverage_error(y_train\u001b[38;5;241m.\u001b[39mvalues, train_scores)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'macro'"
     ]
    }
   ],
   "source": [
    "main('opp115', embedding_method, classifier_object, sim_type, sim_calculation_type, success_metric, 'coverage', 'v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ddee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "main('opp115', embedding_method, classifier_object, sim_type, sim_calculation_type, success_metric, 'coverage', 'v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e572615",
   "metadata": {},
   "outputs": [],
   "source": [
    "main('opp115', embedding_method, classifier_object, sim_type, sim_calculation_type, success_metric, 'coverage', 'v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453970a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "main('opp115', embedding_method, classifier_object, sim_type, sim_calculation_type, success_metric, 'coverage', 'v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27227a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03052345",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "main('opp115', embedding_method, classifier_object, sim_type, sim_calculation_type, success_metric, 'label-ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88df929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab2dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling methods\n",
    "\n",
    "oversample_dataset_v2(num_of_new_instances, X_labeled, y_labeled, X_unlabeled, y_unlabeled, X_test, y_test, sim_calculation_type, batch_size)\n",
    "oversample_dataset_v3(num_of_new_instances, X_labeled, y_labeled, X_unlabeled, y_unlabeled, X_test, y_test, sim_calculation_type, batch_size, n_iter)\n",
    "oversample_dataset_v4(num_of_new_instances, X_labeled, y_labeled, X_unlabeled, y_unlabeled, X_test, y_test, sim_calculation_type, batch_size, n_iter, balance_ratio, success_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-socket",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data in data_paths.keys():\n",
    "    main(data, embedding_method, classifier_object, sim_type, sim_calculation_type, success_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f970f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09141a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9a2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b4bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utilities.read_data(data_paths[data])\n",
    "X = df['text'].apply(preprocess.preprocess_text)\n",
    "y = df.drop(['text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y[col] == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9841b3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
