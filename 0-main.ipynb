{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a701e748",
   "metadata": {},
   "source": [
    "TO DO\n",
    "\n",
    "general implementation\n",
    "    create a graph or diagram to tell whats hapenning\n",
    "    mark all the tasks/steps complete, incomplete, in progress, problems, to do, research etc.\n",
    "    try on a toy problem\n",
    "\n",
    "find new datasets\n",
    "    for different datasets different preprocessing techniques should be applied\n",
    "    RCV1-V2\n",
    "decide on splitting ratio 20 60 20 \n",
    "\n",
    "try different similarity measures \n",
    "    reference paper\n",
    "    cosine\n",
    "    euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b372be",
   "metadata": {},
   "source": [
    "implementation steps\n",
    "\n",
    "1. reading data and preprocessing\n",
    "2. vectorization\n",
    "    2.1 embeddings - will try other embeddings, and will search which one is best for datasets\n",
    "    2.2 dimensionality reduction? (is similarity more accurate when dim. red. done)  - research\n",
    "3. initial classifier to show results\n",
    "4. calculate imbalance ratio and find the ratio of newly labeled data\n",
    "5. oversample dataset using unlabeled set\n",
    "    5.1 find the proper similarity function (eclidean, cosine etc.)\n",
    "        Measurement of Text Similarity: A Survey: a very detailed survey of similarity functions that are used for text data\n",
    "        https://www.kdnuggets.com/2019/01/comparison-text-distance-metrics.html\n",
    "        cosine similarity\n",
    "        minkowski family (euclidean, manhattan)\n",
    "        hamming distance\n",
    "        Jaccard index\n",
    "        Sorensen-dice index\n",
    "        KL divergence\n",
    "        Jensen–Shannon divergence with LDA\n",
    "        Wasserstein distance\n",
    "        SMTP \n",
    "        word mover’s distance\n",
    "    5.2 define a threshold or mechanism to add data for multilabeled set\n",
    "6. train a final classifier to compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "important-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import preprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "import torch\n",
    "from itertools import combinations\n",
    "from sentence_transformers import util\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-packing",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hundred-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1\n",
    "balance_ratio = 0.5\n",
    "sim_type = 'cosine'\n",
    "starting_index = 100_000\n",
    "\n",
    "majority_path = r'C:\\Users\\IsmailKaraman\\workspace\\data\\privacy_policy_data\\OPP-115_v2\\majority.csv'\n",
    "\n",
    "all_columns = ['Data Retention', 'Data Security', 'Do Not Track', 'First Party Collection/Use', \n",
    "             'International and Specific Audiences', 'Introductory/Generic', 'Policy Change', \n",
    "             'Practice not covered', 'Privacy contact information', 'Third Party Sharing/Collection',\n",
    "             'User Access, Edit and Deletion', 'User Choice/Control']\n",
    "\n",
    "sub_col_names = ['Data Security', 'User Access, Edit and Deletion', 'Policy Change']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5df9753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df['text'] = df['text'].apply(preprocess.preprocess_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61d22048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(text, model_name='stsb-roberta-large'):\n",
    "    \n",
    "    from sentence_transformers import util\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import torch\n",
    "    \n",
    "    model = SentenceTransformer(model_name)\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    vectors = model.encode(text, convert_to_tensor=False, device=device)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca5c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    def calculating_class_weights(y_true):\n",
    "        \n",
    "        number_dim = np.shape(y_true)[1]\n",
    "        weights = []\n",
    "        for i in range(number_dim):\n",
    "            at = compute_class_weight('balanced', [0.,1.], y_true[:, i])\n",
    "            weights.append(dict(zip([0,1], at)))\n",
    "            # weights[i] = compute_class_weight('balanced', [0.,1.], y_true[:, i])))\n",
    "        return weights\n",
    "\n",
    "    # class_weights = calculating_class_weights(y_train.values)\n",
    "    \n",
    "    # Linear SVM\n",
    "    linearSvm = OneVsRestClassifier(LogisticRegression(class_weight='balanced'), n_jobs=-1)\n",
    "    linearSvm.fit(X_train, y_train)\n",
    "    linearSvm_preds = linearSvm.predict(X_test)\n",
    "    print_losses(y_test, linearSvm_preds, 'Linear SVM Classifier')\n",
    "    \n",
    "    print(\"\\033[1m\" + 'LinearSVM results: ' + \"\\033[0m\")\n",
    "    print('-'*30)\n",
    "    hamLoss = hamming_loss(y_test.values, linearSvm_preds)\n",
    "    print('hamLoss: {:.2f}'.format(hamLoss))\n",
    "    acc_score = accuracy_score(y_test.values, linearSvm_preds)\n",
    "    print('Exact Match Ratio: {:.2f}'.format(acc_score))\n",
    "    print('-'*30)\n",
    "    print(\"\\033[1m\" + 'Classification Report' + \"\\033[0m\")\n",
    "    print(classification_report(y_test.values, linearSvm_preds, target_names=list(y_test.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "encouraging-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_imb_ratio(y):\n",
    "\n",
    "    class_ratios = (y.sum() / y.shape[0]).values\n",
    "    return class_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fundamental-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_balancing_num_instance_binary(n_samples, n_total_samples, balance_ratio=0.5):\n",
    "    \n",
    "    if n_samples/n_total_samples > balance_ratio:\n",
    "        print(\"Be careful! Given balancing ratio is lower than the class' imbalance ratio\")\n",
    "        \n",
    "    return int((n_total_samples*balance_ratio - n_samples)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "suspended-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_balancing_num_instance_multiclass(y, balance_ratio):\n",
    "    \n",
    "    oversampling_counts = {}\n",
    "    n_samples = y.shape[0]\n",
    "    n_classes = y.shape[1]\n",
    "    \n",
    "    for col in y.columns:\n",
    "        oversampling_counts[col] = cal_balancing_num_instance_binary(y[col].sum(), n_samples, balance_ratio)\n",
    "    \n",
    "    return oversampling_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9bb30db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    if norm1 == 0:\n",
    "        norm1 += 0.00001\n",
    "    if norm2 == 0:\n",
    "        norm2 += 0.00001   \n",
    "    return np.dot(vec1, vec2)/(norm1*norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c0410f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski_similarity(u, v, p=2):\n",
    "    # minkowski distance is a distance measure but we need a similarity function\n",
    "    if p <= 0:\n",
    "        raise ValueError(\"p must be greater than 0\")\n",
    "    u_v = u - v\n",
    "    dist = np.linalg.norm(u_v, ord=p)\n",
    "    if dist == 0:\n",
    "        dist += 0.0001\n",
    "        \n",
    "    return 1/dist #converting a distance to similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d445edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(vec1, vec2, sim_type=sim_type):\n",
    "    \n",
    "    if sim_type == 'cosine':\n",
    "        similarity = cosine_similarity(vec1, vec2)\n",
    "    if sim_type == 'euclidean':\n",
    "        similarity = minkowski_similarity(vec1, vec2, 2)\n",
    "    if sim_type == 'manhattan':\n",
    "        similarity = minkowski_similarity(vec1, vec2, 1)\n",
    "    if sim_type == 'chebychev ':\n",
    "        similarity = minkowski_similarity(vec1, vec2, np.inf)\n",
    "    if sim_type.startswith('minkowski'):\n",
    "        similarity = minkowski_similarity(vec1, vec2, int(sim_type[-1]))\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "564e8408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_within_class_similarity(vecs, sim_type=sim_type):\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for i,j in list(combinations(vecs.index, 2)):\n",
    "        similarities.append(vector_similarity(vecs.loc[i], vecs.loc[j], sim_type))    \n",
    "            \n",
    "    try:\n",
    "        avg_similarity = sum(similarities)/len(similarities)\n",
    "    except AssertionErrors:\n",
    "        print('Error occured')\n",
    "        \n",
    "    return avg_similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91f0de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_between_vector_and_class(vec, class_vecs, sim_type=sim_type):\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for c_vec in class_vecs:\n",
    "        similarities.append(vector_similarity(vec, c_vec, sim_type))\n",
    "    \n",
    "    try:\n",
    "        avg_similarity = sum(similarities)/len(similarities)\n",
    "    except AssertionErrors:\n",
    "        print('Error occured')\n",
    "        \n",
    "    return avg_similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9b50d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_instances(X_labeled, X_unlabeled, class_similarity):\n",
    "    \n",
    "    new_instances = []\n",
    "    \n",
    "    for idx, instance in X_unlabeled.iteritems():\n",
    "        avg_sim = calculate_similarity_between_vector_and_class(instance, X_labeled)\n",
    "        if avg_sim > class_similarity:\n",
    "            new_instances.append(idx)\n",
    "            \n",
    "    return new_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec4f90cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_class_similarities(X, y):\n",
    "    \n",
    "    class_similarities = {}\n",
    "    \n",
    "    for col in y.columns:\n",
    "        indexes = (y[col] == 1).index\n",
    "        \n",
    "        class_similarities[col] = calculate_within_class_similarity(X.loc[indexes]) \n",
    "        \n",
    "    return class_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "704564e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_columns(instance, X_labeled, y_labeled, other_columns):\n",
    "    \n",
    "    other_similarities = {}\n",
    "    \n",
    "    for col_name in other_columns:\n",
    "        \n",
    "        indexes = (y_labeled[col_name] == 1).index\n",
    "        \n",
    "        other_similarities[col_name]  = calculate_similarity_between_vector_and_class(instance, X_labeled.loc[indexes])\n",
    "    \n",
    "    return other_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "legal-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_dataset(num_of_new_instances, X_labeled, y_labeled, X_unlabeled, y_unlabeled):\n",
    "    \n",
    "    # giving priority to mostly imbalanced classes\n",
    "    num_of_new_instances = {k: v for k, v in sorted(num_of_new_instances.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    class_similarities = calculate_overall_class_similarities(X_labeled, y_labeled)\n",
    "    \n",
    "    processed_columns = []\n",
    "    \n",
    "    for col_name, num_instance in num_of_new_instances.items():\n",
    "        \n",
    "        # note: we didnt use num_instance\n",
    "        # the instances will be added should not exceed num_instance\n",
    "        \n",
    "        processed_columns.append(col_name)\n",
    "        \n",
    "        if num_instance == 0:\n",
    "            continue\n",
    "        \n",
    "        indexes = (y_labeled[col_name] == 1).index\n",
    "        \n",
    "        \n",
    "        new_instances = find_new_instances(X_labeled.loc[indexes], X_unlabeled, class_similarities[col_name])\n",
    "        \n",
    "        \n",
    "        for instance_index in new_instances:\n",
    "            \n",
    "            instance_X = X_unlabeled.loc[instance_index]\n",
    "            instance_y = y_unlabeled.loc[instance_index] # note: this is for test case\n",
    "            \n",
    "            # defining all labels as 0s\n",
    "            new_labels = {c:0 for c in all_columns}\n",
    "            # changing col_name's label as 1\n",
    "            new_labels[col_name] = 1\n",
    "            \n",
    "            other_columns = [i for i in all_columns if i not in processed_columns]\n",
    "            other_similarities = find_similar_columns(instance_X, X_labeled, y_labeled, other_columns)\n",
    "            \n",
    "            for col, sim in other_similarities.items():\n",
    "                \n",
    "                if sim > class_similarities[col]:\n",
    "                    new_labels[col] = 1\n",
    "            \n",
    "            # starting index of new instances from a big number\n",
    "            instance_new_index = max(starting_index, max(X_labeled.index)) + 1\n",
    "            instance_X_series = pd.Series(instance_X, index=[instance_new_index])\n",
    "            instance_y_series = pd.Series(instance_y, index=[instance_new_index]) # note: this is for test case\n",
    "            \n",
    "            # adding new instance to labeled set\n",
    "            X_labeled = X_labeled.append(instance_X_series)\n",
    "            y_labeled = y_labeled.append(instance_y_series) # note: this is for test case\n",
    "            \n",
    "            # removing new instance from unlabeled set\n",
    "            X_unlabeled.drop(instance_index, inplace=True)\n",
    "            y_unlabeled.drop(instance_index, inplace=True) # note: this is for test case\n",
    "            \n",
    "    \n",
    "    return X_labeled, y_labeled, X_unlabeled, y_unlabeled "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-george",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "566b277e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Data Retention'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Data Retention'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-13d4e3108480>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m# -----------------------------------------------------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# oversampling dataset using unlabeled data with the given ratios\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m X_labeled, y_labeled, X_unlabeled, y_unlabeled = oversample_dataset(num_of_new_instances, \n\u001b[0m\u001b[0;32m     38\u001b[0m                                                                     X_labeled, y_labeled, X_unlabeled, y_unlabeled)\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# -----------------------------------------------------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-5ca15a710dd7>\u001b[0m in \u001b[0;36moversample_dataset\u001b[1;34m(num_of_new_instances, X_labeled, y_labeled, X_unlabeled, y_unlabeled)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mother_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_columns\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprocessed_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mother_similarities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_similar_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_labeled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_labeled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mother_similarities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-0cf23c8fa246>\u001b[0m in \u001b[0;36mfind_similar_columns\u001b[1;34m(instance, X_labeled, y_labeled, other_columns)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mother_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mindexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_labeled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mother_similarities\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mcalculate_similarity_between_vector_and_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_labeled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Data Retention'"
     ]
    }
   ],
   "source": [
    "# reading data\n",
    "df = pd.read_csv(majority_path)\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# creating a toy dataset to provide efficiency\n",
    "toy_df = df[(df[all_columns].sum(axis=1)==df[sub_col_names].sum(axis=1))].sample(100, random_state=random_state)\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "X = toy_df['text']\n",
    "y = toy_df[sub_col_names]\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# reading from a pickle instead of applying vectorization\n",
    "'''\n",
    "X_num = X.apply(vectorize_data)\n",
    "import pickle\n",
    "with open('X_num.p', 'wb') as f:\n",
    "    pickle.dump(X_num, f)     \n",
    "'''\n",
    "with open('X_num.p', 'rb') as f:\n",
    "    X_num = pickle.load(f)\n",
    "\n",
    "if not np.array_equal(X_num.index, X.index):\n",
    "    assert 'Array indexes are not same'\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# splitting train(labeled-unlabeled)-test\n",
    "# X_num = X.apply(vectorize_data) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_num, y, test_size=0.2, random_state=random_state, stratify=y)\n",
    "X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(X_train, y_train, test_size=0.75, \n",
    "                                                                  stratify=y_train, random_state=random_state)\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# an initial classifier to see results before applying our method\n",
    "# classifier(X_labeled.values, y_labeled, X_test, y_test)\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# calculation number of instances to balance dataset\n",
    "balance_ratio = 0.5\n",
    "num_of_new_instances = cal_balancing_num_instance_multiclass(y_labeled, balance_ratio)\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# oversampling dataset using unlabeled data with the given ratios\n",
    "X_labeled, y_labeled, X_unlabeled, y_unlabeled = oversample_dataset(num_of_new_instances, \n",
    "                                                                    X_labeled, y_labeled, X_unlabeled, y_unlabeled)\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# check if the result gets better\n",
    "classifier(X_labeled.values, y_labeled, X_test, y_test)\n",
    "# -----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "627d62d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_num.p', 'rb') as f:\n",
    "    X_num = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-gnome",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-klein",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-niger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e6f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "all_words = words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1758031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_5len = [word.lower() for word in all_words if len(word)==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-missouri",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for word in words_5len:\n",
    "    if 'h' in word and 'k' in word and 'n' in word:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-behalf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for word in words_5len:\n",
    "    if word.startswith('se') and 'r' in word:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_0 = ''\n",
    "letter_1 = ''\n",
    "letter_2 = 'a'\n",
    "letter_3 = ''\n",
    "letter_4 = ''\n",
    "\n",
    "exist_letters = 'acs'\n",
    "banned_letters = 'trdefou'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [word for word in words_5len for e in exist_letters if e in word]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b866aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [word for word in filtered for b in banned_letters if b in word]\n",
    "filtered = [word for word in filtered if letter_0 and word[0]==letter_0]\n",
    "filtered = [word for word in filtered if letter_1 and word[0]==letter_1]\n",
    "filtered = [word for word in filtered if letter_2 and word[0]==letter_2]\n",
    "filtered = [word for word in filtered if letter_3 and word[0]==letter_3]\n",
    "filtered = [word for word in filtered if letter_4 and word[0]==letter_4]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "if letter_2:\n",
    "    print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ebbe7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for word in words_5len:\n",
    "    if 'o' in word and 'u' in word and 'a' not in word and 'i' not in word and 'd' not in word:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b7269e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
