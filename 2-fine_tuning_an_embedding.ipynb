{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50cd132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utilities\n",
    "import preprocess\n",
    "import similarities\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings =  ['stsb-roberta-large',\n",
    "                        'all-MiniLM-L6-v2',\n",
    "                        'all-MiniLM-L12-v2',\n",
    "                        'all-mpnet-base-v2',\n",
    "                        'all-distilroberta-v1',\n",
    "                        'bert-base-nli-mean-tokens',\n",
    "                        'distiluse-base-multilingual-cased-v1',\n",
    "                        'distilbert-base-nli-mean-tokens',\n",
    "                        'multi-qa-mpnet-base-dot-v1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-participant",
   "metadata": {},
   "source": [
    "microsoft/mpnet-base\t60.99\n",
    "nghuyong/ernie-2.0-en\t60.73\n",
    "microsof/deberta-base\t60.21\n",
    "roberta-base\t59.63\n",
    "t5-base\t59.21\n",
    "bert-base-uncased\t59.17\n",
    "distilbert-base-uncased\t59.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47826c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'opp115'\n",
    "random_state = 1\n",
    "\n",
    "embedding_method = 'stsb-roberta-large'#'distilbert-base-nli-mean-tokens'\n",
    "np.random.seed(random_state)\n",
    "data_paths = {'opp115'   : r'C:\\Users\\IsmailKaraman\\workspace\\data\\privacy_policy_data\\OPP-115_v2\\majority.csv',\n",
    "              'ohsumed'  : r'C:\\Users\\IsmailKaraman\\workspace\\GitHub\\thesis\\data\\ohsumed.csv',\n",
    "              'reuters'  : r'C:\\Users\\IsmailKaraman\\workspace\\GitHub\\thesis\\data\\Reuters21578.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497097fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utilities.read_data(data_paths[data])\n",
    "X = df['text'].apply(preprocess.preprocess_text)\n",
    "y = df.drop(['text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ea420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_between_class_similarities(col1, col2, X, y):\n",
    "    \n",
    "    sims = []\n",
    "    \n",
    "    for idx1 in y[y[col1]==1].index:\n",
    "        for idx2 in y[y[col2]==1].index:\n",
    "            sims.append(similarities.vector_similarity(X.loc[idx1], X.loc[idx2]))\n",
    "    \n",
    "    return sum(sims)/len(sims)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c0fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_matrix(X, y, sim_method='cosine'):\n",
    "    \n",
    "    import similarities\n",
    "    \n",
    "    sim_df = pd.DataFrame(index=y.columns, columns=y.columns)\n",
    "    \n",
    "    for col in y.columns:\n",
    "    \n",
    "        indexes = y[y[col]==1].index\n",
    "        sim_df.loc[col, col] = similarities.calculate_within_class_similarity(X.loc[indexes], 'average')\n",
    "    \n",
    "    for col1, col2 in list(combinations(y.columns, 2)):\n",
    "        sim_df.loc[col1, col2] = calculate_between_class_similarities(col1, col2, X, y)\n",
    "    \n",
    "    return sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = utilities.vectorize_data(X, embedding_method)\n",
    "X_num = pd.Series([np.squeeze(i) for i in X_num])\n",
    "sim_df = calculate_similarity_matrix(X_num, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fa69ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l_sum = 100*np.diag(sim_df).sum()/12 - (sim_df.sum().sum()-np.diag(sim_df).sum())/66\n",
    "print(f'{l_sum:.2f}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73408fdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "sns.heatmap(sim_df.fillna(0), annot=True,\n",
    "xticklabels=sim_df.columns,\n",
    "yticklabels=sim_df.columns, cmap=\"rocket_r\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "\n",
    "for col in y.columns:\n",
    "    \n",
    "    idxs = y[y[col]==1].index\n",
    "    tmp_set = X.loc[idxs].sample(sample_size)\n",
    "    \n",
    "    for pair in combinations(tmp_set, 2):\n",
    "        train_set.append(InputExample(texts=list(pair), label=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1, col2 in combinations(y.columns,2):\n",
    "    idxs1 = y[y[col1]==1].index\n",
    "    idxs2 = y[y[col2]==1].index\n",
    "    tmp_set1 = X.loc[idxs1].sample(int(sample_size/2))\n",
    "    tmp_set2 = X.loc[idxs2].sample(int(sample_size/2))\n",
    "    \n",
    "    for pair in zip(tmp_set1, tmp_set2):\n",
    "        train_set.append(InputExample(texts=list(pair), label=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(embedding_method, device='cuda') # stsb-roberta-large\n",
    "\n",
    "train_dataloader = DataLoader(train_set, shuffle=True, batch_size=16)\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=10, warmup_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(text, model):\n",
    "    \n",
    "    # model = SentenceTransformer(model_name)\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    vectors = model.encode(text, convert_to_tensor=False, device=device)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-video",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_num_tuned = vectorize_data(X, model)\n",
    "X_num_tuned = pd.Series([np.squeeze(i) for i in X_num_tuned])\n",
    "sim_df_after = calculate_similarity_matrix(X_num_tuned, y)\n",
    "\n",
    "sum_after = 100*np.diag(sim_df_after).sum()/12 - (sim_df_after.sum().sum()-np.diag(sim_df_after).sum())/66\n",
    "print(f'{sum_after:.2f}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "sns.heatmap(sim_df_after.fillna(0), annot=True,\n",
    "xticklabels=sim_df.columns,\n",
    "yticklabels=sim_df.columns, cmap=\"rocket_r\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-syntax",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
