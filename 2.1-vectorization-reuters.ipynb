{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "referring for articles:\n",
    "https://www.sbert.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocess\n",
    "import utilities\n",
    "import similarities\n",
    "import parameters\n",
    "import seaborn as sns\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = parameters.data_paths\n",
    "sim_calculation_type = parameters.sim_calculation_type\n",
    "all_sentence_embeddings =  parameters.huggingface_embeddings + parameters.openai_embeddings + parameters.google_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_between_class_similarities(col1, col2, X, y):\n",
    "    \n",
    "    sims = []\n",
    "    \n",
    "    for idx1 in y[y[col1]==1].index:\n",
    "        for idx2 in y[y[col2]==1].index:\n",
    "            sims.append(similarities.vector_similarity(X.loc[idx1], X.loc[idx2]))\n",
    "    \n",
    "    return sum(sims)/len(sims)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_matrix(X, y, sim_method='cosine'):\n",
    "    \n",
    "    import similarities\n",
    "    \n",
    "    sim_df = pd.DataFrame(index=y.columns, columns=y.columns)\n",
    "    \n",
    "    for col in y.columns:\n",
    "    \n",
    "        indexes = y[y[col]==1].index\n",
    "        sim_df.loc[col, col] = similarities.calculate_within_class_similarity(X.loc[indexes], sim_calculation_type)\n",
    "    \n",
    "    for col1, col2 in list(combinations(y.columns, 2)):\n",
    "        sim_df.loc[col1, col2] = calculate_between_class_similarities(col1, col2, X, y)\n",
    "    \n",
    "    return sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'opp115': 'C:\\\\Users\\\\IsmailKaraman\\\\workspace\\\\GitHub\\\\thesis\\\\data\\\\opp-115.csv',\n",
       " 'ohsumed': 'C:\\\\Users\\\\IsmailKaraman\\\\workspace\\\\GitHub\\\\thesis\\\\data\\\\ohsumed.csv',\n",
       " 'reuters': 'C:\\\\Users\\\\IsmailKaraman\\\\workspace\\\\GitHub\\\\thesis\\\\data\\\\Reuters21578.csv'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_file = 'embedding_results_reuters.p'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\n",
    "results = {}\n",
    "with open(res_file, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(res_file, 'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▌                                                                           | 1/31 [21:34<10:47:23, 1294.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!  all-mpnet-base-v1  failed ... \n"
     ]
    }
   ],
   "source": [
    "data = 'reuters'\n",
    "path = data_paths[data]\n",
    "\n",
    "    \n",
    "df = utilities.read_data(path)\n",
    "X = df['text']\n",
    "y = df.drop(['text'], axis=1)\n",
    "X = X.apply(preprocess.preprocess_text)\n",
    "\n",
    "import pickle\n",
    "with open(res_file, 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "iterate = [i for i in all_sentence_embeddings if i not in results.keys()]\n",
    "results['failed_embedings'] = []\n",
    "\n",
    "for embedding_method in tqdm(iterate):\n",
    "\n",
    "    try:\n",
    "        X_num = utilities.vectorize_data(X, embedding_method)\n",
    "        sim_df = calculate_similarity_matrix(X_num, y)\n",
    "        results[embedding_method] = sim_df\n",
    "        print(embedding_method, ' completed ... ')\n",
    "    except:\n",
    "        print('!!!! ',embedding_method, ' failed ... ')\n",
    "        results['failed_embedings'].append(embedding_method)\n",
    "    \n",
    "    with open(res_file, 'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('embedding_results_opp115.p', 'rb') as f:\n",
    "    results_opp115 = pickle.load(f)\n",
    "results_opp115.pop('failed_embedings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_matrix_score(sim_df):\n",
    "    scores = []\n",
    "    for col in sim_df.columns:\n",
    "        scores.append((sim_df.loc[col, col] - sim_df.loc[col].drop(col).max())/sim_df.loc[col, col])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best:\n",
    "'paraphrase-MiniLM-L6-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed = ['nlpaueb/legal-bert-base-uncased',\n",
    "'bert-base-uncased',\n",
    "'albert-base-v2',\n",
    "'bert-base-nli-mean-tokens',\n",
    "'distilbert-base-nli-mean-tokens',\n",
    "'saibo/legal-roberta-base',\n",
    "'sentence-t5-large',\n",
    "'sentence-transformers/average_word_embeddings_glove.6B.300d',\n",
    "'sentence-transformers/average_word_embeddings_glove.840B.300d',\n",
    "'text-similarity-babbage-001',\n",
    "'text-similarity-ada-001',\n",
    "'text-similarity-curie-001',\n",
    "'all-MiniLM-L12-v2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = results_opp115.copy()\n",
    "finel_res = {v:k for v, k in res.items() if v not in removed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for embedding, sim_df in finel_res.items():\n",
    "    scores = calculate_matrix_score(sim_df)\n",
    "    scores = scores[:-1]\n",
    "    print(f'{embedding} --- max: {max(scores):.2f}, min: {min(scores):.2f}, avg: {sum(scores)/len(scores):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for embedding, sim_df in results_opp115.items():\n",
    "    \n",
    "    plt.figure(i)\n",
    "    plt.title(f'{embedding}')\n",
    "    sns.heatmap(sim_df.fillna(0), annot=True,\n",
    "    xticklabels=sim_df.columns,\n",
    "    yticklabels=sim_df.columns, cmap=\"rocket_r\")\n",
    "    \n",
    "\n",
    "    plt.show()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\\\"nlpaueb/legal-bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"saibo/legal-roberta-base\")\n",
    "                                  \n",
    "tokenizer = AutoTokenizer.from_pretrained('saibo/legal-roberta-base')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = 'I really love to play football'\n",
    "sentence2 = 'Playing football is my passion.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_sentence(sentence1, sentence2, model, preprocessing=False):\n",
    "    \n",
    "    model = SentenceTransformer(model)\n",
    "    \n",
    "    if preprocessing:\n",
    "        import preprocess\n",
    "        sentence1 = preprocess.preprocess_text(sentence1)\n",
    "        sentence2 = preprocess.preprocess_text(sentence2)\n",
    "        \n",
    "    embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "    embedding2 = model.encode(sentence2, convert_to_tensor=True)\n",
    "    \n",
    "    cosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "    \n",
    "    return cosine_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \n",
    "'saibo/legal-roberta-base'\n",
    "'nlpaueb/legal-bert-base-uncased'\n",
    "'nlpaueb/legal-bert-small-uncased'\n",
    "'saibo/legal-roberta-base'\n",
    "'albert-base-v2'\n",
    "'ALBERT-xlarge'\n",
    "'ALBERT-xxlarg'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)    \n",
    "text_tensor1 = tokenizer.encode(sentence1, padding=True, truncation=True, return_tensors='pt')\n",
    "text_tensor1 = tokenizer.encode(sentence2, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    output1 = model(text_tensor1)\n",
    "    output2 = model(text_tensor2)\n",
    "\n",
    "sentence_embeddings1 = mean_pooling(output1, text_tensor1)\n",
    "sentence_embeddings2 = mean_pooling(output2, text_tensor2)\n",
    "\n",
    "cosine_scores = util.pytorch_cos_sim(sentence_embeddings1, sentence_embeddings2)\n",
    "\n",
    "print(cosine_scores.item())\n",
    "\n",
    "print(sentence_embeddings1.shape, sentence_embeddings2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('stsb-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = 'I love to play football because I am a player'\n",
    "sentence2 = 'Playing football is my passion.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "embedding2 = model.encode(sentence2, convert_to_tensor=True)\n",
    "cosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "print(cosine_scores.item())\n",
    "\n",
    "embedding1 = model.encode(preprocess.preprocess_text(sentence1), convert_to_tensor=True)\n",
    "embedding2 = model.encode(preprocess.preprocess_text(sentence2), convert_to_tensor=True)\n",
    "cosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "print(cosine_scores.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://medium.com/nlplanet/two-minutes-nlp-11-word-embeddings-models-you-should-know-a0581763b9a9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"http://www.scielo.org.mx/scielo.php?script=sci_arttext&pid=S1405-55462016000400647\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import sub\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.downloader as api\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.similarities import WordEmbeddingSimilarityIndex\n",
    "from gensim.similarities import SparseTermSimilarityMatrix\n",
    "from gensim.similarities import SoftCosineSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = 'fruit and vegetables'\n",
    "documents = ['cars drive on the road', 'tomatoes are actually fruit']\n",
    "\n",
    "stopwords = ['the', 'and', 'are', 'a']\n",
    "\n",
    "# From: https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/soft_cosine_tutorial.ipynb\n",
    "def preprocess(doc):\n",
    "    # Tokenize, clean up input document string\n",
    "    doc = sub(r'<img[^<>]+(>|$)', \" image_token \", doc)\n",
    "    doc = sub(r'<[^<>]+(>|$)', \" \", doc)\n",
    "    doc = sub(r'\\[img_assist[^]]*?\\]', \" \", doc)\n",
    "    doc = sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', \" url_token \", doc)\n",
    "    return [token for token in simple_preprocess(doc, min_len=0, max_len=float(\"inf\")) if token not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = 'fruit and vegetables'\n",
    "documents = ['cars drive on the road', 'tomatoes are actually fruit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"I like Python because I can build AI applications\",\n",
    "          \"I like Python because I can do data analytics\",\n",
    "          \"The cat sits on the ground\",\n",
    "         \"The cat walks on the sidewalk\"]\n",
    "\n",
    "query_string = \"I like Javascript because I can build web applications\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the documents, including the query string\n",
    "corpus = [preprocess(document) for document in documents]\n",
    "query = preprocess(query_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model: this is a big file, can take a while to download and open\n",
    "glove = api.load(\"glove-wiki-gigaword-50\")    \n",
    "similarity_index = WordEmbeddingSimilarityIndex(glove)\n",
    "\n",
    "# Build the term dictionary, TF-idf model\n",
    "dictionary = Dictionary(corpus+[query])\n",
    "tfidf = TfidfModel(dictionary=dictionary)\n",
    "\n",
    "# Create the term similarity matrix.  \n",
    "similarity_matrix = SparseTermSimilarityMatrix(similarity_index, dictionary, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Soft Cosine Measure between the query and the documents.\n",
    "# From: https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/soft_cosine_tutorial.ipynb\n",
    "query_tf = tfidf[dictionary.doc2bow(query)]\n",
    "\n",
    "index = SoftCosineSimilarity(\n",
    "            tfidf[[dictionary.doc2bow(document) for document in corpus]],\n",
    "            similarity_matrix)\n",
    "\n",
    "doc_similarity_scores = index[query_tf]\n",
    "\n",
    "# Output the sorted similarity scores and documents\n",
    "sorted_indexes = np.argsort(doc_similarity_scores)[::-1]\n",
    "for idx in sorted_indexes:\n",
    "    print(f'{idx} \\t {doc_similarity_scores[idx]:0.3f} \\t {documents[idx]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http://www.scielo.org.mx/scielo.php?script=sci_arttext&pid=S1405-55462016000400647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
