balancing mechanism 
    + averaging and multiplying with a threshold_factor
    + 0.75 quartile
    - more needed
        
   
iterative process to check improvement
    + only for the affected labels, the labels that are found during the oversampling
    maybe AL can be included
    similarity factor
        each time change threshold with a logic like simulated annealing
        threshold can be tuned with with the results of the iterative classifier
    
try different similarity metrics

find the most effective embedding method

define a stopping condition
- now num of req instances to balance a class is calculated and split into batches but a batch is added if it improves the f1, it may not add instance
- it should be like, I searched all the data and stop if no improvement, or iteration

similairty-distance relation 
    -from Applied multivariate statistical analysis
        s = 1/(1+d)
        d = (2*(1-s))^0.5
    -s = 1 / d
    -s = 1 / (d+1)
    -s = 1 / e^d 
    -normed
        a. find norm: d_norm = distance / max(distance)
        b. similarity = 1 - d_norm

stopping condition
- calculate similarity as average and multiply it with a threshold, this threshold should be defined for every class

notes:
-during oversampling we calculate class similarities only with labeled set and we use it in each iteration during oversampling
recalculating it in each iteration after new instances are added may help!



Parameters
    calculation_type - category
        'average' : calculates avg. similarity
        'safe_interval' : finds 0.75 quartile
    batch_size - int
        -1 : finds all possible instances
        >0 : uses batchs





