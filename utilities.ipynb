{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41230a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import preprocess\n",
    "import similarities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import hamming_loss, accuracy_score, classification_report\n",
    "from sentence_transformers import util, SentenceTransformer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4754348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df['text'] = df['text'].apply(preprocess.preprocess_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103f78b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(text, model_name='stsb-roberta-large'):\n",
    "    \n",
    "    model = SentenceTransformer(model_name)\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    vectors = model.encode(text, convert_to_tensor=False, device=device)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca96b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculating_class_weights(y_true):\n",
    "        \n",
    "        number_dim = np.shape(y_true)[1]\n",
    "        weights = []\n",
    "        for i in range(number_dim):\n",
    "            weights.append(dict(zip([0,1], compute_class_weight('balanced', [0.,1.], y_true[:, i]))))\n",
    "            # weights[i] = compute_class_weight('balanced', [0.,1.], y_true[:, i])))\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661ef252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    # class_weights = calculating_class_weights(y_train.values)\n",
    "    \n",
    "    # Linear SVM\n",
    "    model = OneVsRestClassifier(LinearSVC(class_weight='balanced'), n_jobs=-1)\n",
    "    model.fit(X_train, y_train.values)\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    print(\"\\033[1m\" + 'LinearSVM results: ' + \"\\033[0m\")\n",
    "    print('-'*30)\n",
    "    hamLoss = hamming_loss(y_test.values, preds)\n",
    "    print('hamLoss: {:.2f}'.format(hamLoss))\n",
    "    acc_score = accuracy_score(y_test.values, preds)\n",
    "    print('Exact Match Ratio: {:.2f}'.format(acc_score))\n",
    "    print('-'*30)\n",
    "    print(\"\\033[1m\" + 'Classification Report' + \"\\033[0m\")\n",
    "    print(classification_report(y_test.values, preds, target_names=list(y_test.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaebabb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_imb_ratio(y):\n",
    "\n",
    "    class_ratios = (y.sum() / y.shape[0]).values\n",
    "    return class_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f01974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_balancing_num_instance_binary(n_samples, n_total_samples, balance_ratio=0.5):\n",
    "    \n",
    "    if n_samples/n_total_samples > balance_ratio:\n",
    "        print(\"Be careful! Given balancing ratio is lower than the class' imbalance ratio\")\n",
    "        \n",
    "    return int((n_total_samples*balance_ratio - n_samples)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9ce2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_balancing_num_instance_multiclass(y, balance_ratio):\n",
    "    \n",
    "    oversampling_counts = {}\n",
    "    n_samples = y.shape[0]\n",
    "    n_classes = y.shape[1]\n",
    "    \n",
    "    for col in y.columns:\n",
    "        oversampling_counts[col] = calculate_balancing_num_instance_binary(y[col].sum(), n_samples, balance_ratio)\n",
    "    \n",
    "    return oversampling_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ad7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_instances(X_labeled, X_unlabeled, class_similarity):\n",
    "    \n",
    "    new_instances = []\n",
    "    \n",
    "    for idx, instance in X_unlabeled.iteritems():\n",
    "        avg_sim = similarities.calculate_similarity_between_vector_and_class(instance, X_labeled)\n",
    "        if avg_sim > class_similarity:\n",
    "            new_instances.append(idx)\n",
    "            \n",
    "    return new_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb876600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_columns(instance, X_labeled, y_labeled, other_columns):\n",
    "    \n",
    "    other_similarities = {}\n",
    "    \n",
    "    for col_name in other_columns:\n",
    "        \n",
    "        indexes = (y_labeled[col_name] == 1).index\n",
    "        \n",
    "        other_similarities[col_name]  = similarities.calculate_similarity_between_vector_and_class(instance, X_labeled.loc[indexes])\n",
    "    \n",
    "    return other_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2419c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_dataset(num_of_new_instances, X_labeled, y_labeled, X_unlabeled, y_unlabeled):\n",
    "    \n",
    "    # giving priority to mostly imbalanced classes\n",
    "    num_of_new_instances = {k: v for k, v in sorted(num_of_new_instances.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    class_similarities = similarities.calculate_overall_class_similarities(X_labeled, y_labeled)\n",
    "    \n",
    "    processed_columns = []\n",
    "    \n",
    "    validation = {}\n",
    "    val_idx = 0\n",
    "    \n",
    "    for col_name, num_instance in num_of_new_instances.items():\n",
    "        \n",
    "        # note: we didnt use num_instance\n",
    "        # the instances will be added should not exceed num_instance\n",
    "        \n",
    "        processed_columns.append(col_name)\n",
    "        \n",
    "        if num_instance == 0:\n",
    "            continue\n",
    "        \n",
    "        indexes = (y_labeled[y_labeled[col_name] == 1]).index\n",
    "        new_instances = find_new_instances(X_labeled.loc[indexes], X_unlabeled, class_similarities[col_name])\n",
    "        \n",
    "        for instance_index in new_instances:\n",
    "            \n",
    "            instance_X = X_unlabeled.loc[instance_index]\n",
    "            instance_y = y_unlabeled.loc[instance_index] # note: this is for test case\n",
    "            \n",
    "            # defining all labels as 0s\n",
    "            new_labels = {c:0 for c in all_columns}\n",
    "            # changing col_name's label as 1\n",
    "            new_labels[col_name] = 1\n",
    "            \n",
    "            ### finding other labels\n",
    "            other_columns = [i for i in all_columns if i not in processed_columns]\n",
    "            other_similarities = find_similar_columns(instance_X, X_labeled, y_labeled, other_columns)\n",
    "            for col, sim in other_similarities.items():\n",
    "                if sim > class_similarities[col]:\n",
    "                    new_labels[col] = 1\n",
    "            \n",
    "            ### appending data to unlabeled set and removing it from unlabeled set\n",
    "            # starting index of new instances from a big number\n",
    "            instance_new_index = max(starting_index, max(X_labeled.index)) + 1\n",
    "            instance_X_series = pd.Series([instance_X], index=[instance_new_index])\n",
    "            instance_new_labels =pd.DataFrame(new_labels, index=[instance_new_index])\n",
    "            # adding new instance to labeled set\n",
    "            X_labeled = pd.concat([X_labeled, instance_X_series])\n",
    "            y_labeled = pd.concat([y_labeled, instance_new_labels])\n",
    "            # removing new instance from unlabeled set\n",
    "            X_unlabeled.drop(instance_index, inplace=True)\n",
    "            y_unlabeled.drop(instance_index, inplace=True) # note: this is for test case\n",
    "            \n",
    "            # validation\n",
    "            validation[val_idx] = (col_name, instance_index, instance_X, (instance_y), new_labels)\n",
    "            val_idx += 1\n",
    "    \n",
    "    return validation, X_labeled, y_labeled, X_unlabeled, y_unlabeled "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
